{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df = pd.read_csv('../../../Stock_Data/Data/stock_df/date_list.csv')\n",
    "del date_df['Unnamed: 0']\n",
    "del date_df['article']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df = date_df[date_df['Date'] <= '2019-12-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14695</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14696</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14697</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14698</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14699</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14700 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date  Category\n",
       "0      2014-01-02         2\n",
       "1      2014-01-02         3\n",
       "2      2014-01-02         4\n",
       "3      2014-01-02         5\n",
       "4      2014-01-02         6\n",
       "...           ...       ...\n",
       "14695  2019-12-30         7\n",
       "14696  2019-12-30         8\n",
       "14697  2019-12-30         9\n",
       "14698  2019-12-30        10\n",
       "14699  2019-12-30        11\n",
       "\n",
       "[14700 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cj_article = pd.read_csv('../../../Sentiment Analysis/handmade_sentitest/trainingset/CJ제일제당_traintestdata_3300.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>에너지공단, '2019년 ESP 성과공유 워크숍' 개최</td>\n",
       "      <td>2019.11.22</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[공직자 재산공개] 조국 민정수석, '1800만원 VS 1억원' 아까운 선택(종합)</td>\n",
       "      <td>2018.03.29</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[공직자 재산공개] 조국 민정수석, '1800만원 VS 1억원' 아까운 선택</td>\n",
       "      <td>2018.03.29</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CJ제일제당, 임산부 직원 배려하는 조직문화 강화</td>\n",
       "      <td>2018.03.12</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>이건희 동영상' 촬영·협박 CJ 前부장 1심서 징역 4년6개월</td>\n",
       "      <td>2017.08.25</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3308</th>\n",
       "      <td>3308</td>\n",
       "      <td>클라라 사촌 이래나씨, CJ그룹 이선호씨와 결혼 ‘지덕체 겸비한 엄친딸’</td>\n",
       "      <td>2016.03.25</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3309</th>\n",
       "      <td>3309</td>\n",
       "      <td>CJ그룹 이재현 회장의 장남 이선호씨, 클라라 사촌과 결혼</td>\n",
       "      <td>2016.03.25</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3310</th>\n",
       "      <td>3310</td>\n",
       "      <td>더 예뻐진 박보람, \"다이어트엔 지름길 없어…'이것'이 중요하다\"</td>\n",
       "      <td>2015.03.20</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3311</th>\n",
       "      <td>3311</td>\n",
       "      <td>CJ 채용, 18일 오후 6시 마감…지원 자격과 채용 분야는?</td>\n",
       "      <td>2014.03.17</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3312</th>\n",
       "      <td>3312</td>\n",
       "      <td>[소치]이광기·김호준, 스노보드 하프파이프 준결선행 좌절</td>\n",
       "      <td>2014.02.11</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3313 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                           Title        Date  \\\n",
       "0              0                  에너지공단, '2019년 ESP 성과공유 워크숍' 개최  2019.11.22   \n",
       "1              1  [공직자 재산공개] 조국 민정수석, '1800만원 VS 1억원' 아까운 선택(종합)  2018.03.29   \n",
       "2              2      [공직자 재산공개] 조국 민정수석, '1800만원 VS 1억원' 아까운 선택  2018.03.29   \n",
       "3              3                     CJ제일제당, 임산부 직원 배려하는 조직문화 강화  2018.03.12   \n",
       "4              4              이건희 동영상' 촬영·협박 CJ 前부장 1심서 징역 4년6개월  2017.08.25   \n",
       "...          ...                                             ...         ...   \n",
       "3308        3308        클라라 사촌 이래나씨, CJ그룹 이선호씨와 결혼 ‘지덕체 겸비한 엄친딸’  2016.03.25   \n",
       "3309        3309                CJ그룹 이재현 회장의 장남 이선호씨, 클라라 사촌과 결혼  2016.03.25   \n",
       "3310        3310            더 예뻐진 박보람, \"다이어트엔 지름길 없어…'이것'이 중요하다\"  2015.03.20   \n",
       "3311        3311              CJ 채용, 18일 오후 6시 마감…지원 자격과 채용 분야는?  2014.03.17   \n",
       "3312        3312                 [소치]이광기·김호준, 스노보드 하프파이프 준결선행 좌절  2014.02.11   \n",
       "\n",
       "      Category label  \n",
       "0            2     0  \n",
       "1            2     0  \n",
       "2            2     1  \n",
       "3            2    -1  \n",
       "4            2     1  \n",
       "...        ...   ...  \n",
       "3308        11     0  \n",
       "3309        11     0  \n",
       "3310        11     0  \n",
       "3311        11     0  \n",
       "3312        11     0  \n",
       "\n",
       "[3313 rows x 5 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cj_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/py/stock_trading_agent/article_df/selected20/SK텔레콤_df.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-99f7ff3b21c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#print(index)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0marticle_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'C:/py/stock_trading_agent/article_df/selected20/{}_df.csv'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkospi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0marticle_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Unnamed: 0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0marticle_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marticle_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Title'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'first'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2008\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/py/stock_trading_agent/article_df/selected20/SK텔레콤_df.csv'"
     ]
    }
   ],
   "source": [
    "kospi20=['SK텔레콤','LG전자','이마트','기아차','SK하이닉스','한국전력',\\\n",
    "'현대백화점','셀트리온','KB금융','LG화학','아모레퍼시픽','기업은행','현대모비스','대우조선해양','GS건설',\\\n",
    "'S-Oil','CJ제일제당', '삼성전자','현대차','대한항공']\n",
    "\n",
    "for index, kospi in enumerate(kospi20):\n",
    "    #print(index)\n",
    "    num = index+1\n",
    "    article_df = pd.read_csv('C:/py/stock_trading_agent/article_df/selected20/{}_df.csv'.format(kospi))\n",
    "    del article_df['Unnamed: 0']\n",
    "    article_df = article_df.drop_duplicates('Title',keep = 'first')\n",
    "    article_df = article_df.drop(article_df[article_df['Date'] == '2019.12.31'].index)\n",
    "    article_df = article_df.dropna(axis=0)\n",
    "    article_df = article_df.reset_index(drop=True)\n",
    "    #print(len(article_df))\n",
    "    for i in range(len(article_df)):\n",
    "        #print(i)\n",
    "        article_df['Date'][i] = article_df['Date'][i].replace('.','-')\n",
    "    article_df = article_df.sort_values('Date')\n",
    "\n",
    "    \n",
    "    while True:\n",
    "        index = article_df['Date'].isin(date_df['Date']) == False\n",
    "        holidays = article_df['Date'][index]\n",
    "        #print(len(holidays))\n",
    "        if len(holidays) == 0:\n",
    "            break\n",
    "        else:\n",
    "            for i in range(len(holidays)):\n",
    "                holiday = holidays.iloc[i]\n",
    "                conv_hd = datetime.datetime.strptime(holiday,'%Y-%m-%d')\n",
    "                not_holiday = str(conv_hd + datetime.timedelta(days=1))[:10]\n",
    "                holidays.iloc[i] = not_holiday\n",
    "            article_df['Date'][index] = holidays \n",
    "    \n",
    "    merge_df = pd.merge(date_df, article_df, left_on=['Date','Category'], right_on=['Date','Category'], how='left')\n",
    "    \n",
    "    # one-hot encoding\n",
    "    merge_df['politics']=0\n",
    "    merge_df['economics']=0\n",
    "    merge_df['IT']=0\n",
    "    merge_df['finance']=0\n",
    "    merge_df['realEstate']=0\n",
    "    merge_df['international']=0\n",
    "    merge_df['social']=0\n",
    "    merge_df['life']=0\n",
    "    merge_df['golf']=0\n",
    "    merge_df['ent']=0\n",
    "\n",
    "    for i in range(len(merge_df)):\n",
    "        if merge_df['Category'][i] == 2:\n",
    "            merge_df['politics'][i] = 1\n",
    "        elif merge_df['Category'][i] == 3:\n",
    "            merge_df['economics'][i] = 1\n",
    "        elif merge_df['Category'][i] == 4:\n",
    "            merge_df['IT'][i] = 1\n",
    "        elif merge_df['Category'][i] == 5:\n",
    "            merge_df['finance'][i] = 1\n",
    "        elif merge_df['Category'][i] == 6:\n",
    "            merge_df['realEstate'][i] = 1\n",
    "        elif merge_df['Category'][i] == 7:\n",
    "            merge_df['international'][i] = 1\n",
    "        elif merge_df['Category'][i] == 8:\n",
    "            merge_df['social'][i] = 1\n",
    "        elif merge_df['Category'][i] == 9:\n",
    "            merge_df['life'][i] = 1\n",
    "        elif merge_df['Category'][i] == 10:\n",
    "            merge_df['golf'][i] = 1\n",
    "        elif merge_df['Category'][i] == 11:\n",
    "            merge_df['ent'][i] = 1\n",
    "        #print(i)\n",
    "\n",
    "    del merge_df['Category']    \n",
    "    merge_df.to_csv('C:/py/stock_trading_agent/article_df/selected20/{index}. {name}_df_V2.csv'.format(index=num,name=kospi), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>현대H몰, '설맞이 선물 대잔치' 특집전</td>\n",
       "      <td>2014-01-07</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858</th>\n",
       "      <td>CJ제일제당, 실속 설 선물세트 130종 출시</td>\n",
       "      <td>2014-01-08</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1857</th>\n",
       "      <td>CJ제일제당, 해외 수출용 '다시다 닭고기' 국내 출시</td>\n",
       "      <td>2014-01-09</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856</th>\n",
       "      <td>CJ, 경력단절 여성 재취업 프로젝트 'CJ리턴십' 2기 모집</td>\n",
       "      <td>2014-01-09</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853</th>\n",
       "      <td>[슈퍼스타P]스킨케어의 진정한 마무리…속부터 탄탄한 피부</td>\n",
       "      <td>2014-01-10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>이달 식품 상장기업 브랜드평판 1위는 '오리온'</td>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>비상경영' CJ, 내실 위한 인사 단행…K푸드 주역 강신호, 제당 대표이사로</td>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[인사]CJ그룹 정기 임원인사</td>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>홈플러스, 새해 첫날 '빅딜데이'…상품 300여종 최대 반값 할인</td>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>CJ씨푸드, CJ제일제당과 1476억 규모 공급계약 체결</td>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2418 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Title        Date  Category label\n",
       "1859                      현대H몰, '설맞이 선물 대잔치' 특집전  2014-01-07         4     1\n",
       "1858                   CJ제일제당, 실속 설 선물세트 130종 출시  2014-01-08         4     1\n",
       "1857              CJ제일제당, 해외 수출용 '다시다 닭고기' 국내 출시  2014-01-09         4     1\n",
       "1856          CJ, 경력단절 여성 재취업 프로젝트 'CJ리턴십' 2기 모집  2014-01-09         4     1\n",
       "1853             [슈퍼스타P]스킨케어의 진정한 마무리…속부터 탄탄한 피부  2014-01-10         4     0\n",
       "...                                          ...         ...       ...   ...\n",
       "23                    이달 식품 상장기업 브랜드평판 1위는 '오리온'  2019-12-30         3    -1\n",
       "21    비상경영' CJ, 내실 위한 인사 단행…K푸드 주역 강신호, 제당 대표이사로  2019-12-30         3     1\n",
       "22                              [인사]CJ그룹 정기 임원인사  2019-12-30         3     0\n",
       "20          홈플러스, 새해 첫날 '빅딜데이'…상품 300여종 최대 반값 할인  2019-12-30         3     1\n",
       "1860             CJ씨푸드, CJ제일제당과 1476억 규모 공급계약 체결  2019-12-30         5     1\n",
       "\n",
       "[2418 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/.local/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/test/.local/lib/python3.6/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/test/.local/lib/python3.6/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/test/.local/lib/python3.6/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/test/.local/lib/python3.6/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/test/.local/lib/python3.6/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/test/.local/lib/python3.6/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/test/.local/lib/python3.6/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/test/.local/lib/python3.6/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/test/.local/lib/python3.6/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/test/.local/lib/python3.6/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/test/.local/lib/python3.6/site-packages/ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/test/.local/lib/python3.6/site-packages/ipykernel_launcher.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/test/.local/lib/python3.6/site-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/test/.local/lib/python3.6/site-packages/ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/test/.local/lib/python3.6/site-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/test/.local/lib/python3.6/site-packages/ipykernel_launcher.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/test/.local/lib/python3.6/site-packages/ipykernel_launcher.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/test/.local/lib/python3.6/site-packages/ipykernel_launcher.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/test/.local/lib/python3.6/site-packages/ipykernel_launcher.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/test/.local/lib/python3.6/site-packages/ipykernel_launcher.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "article_df = cj_article\n",
    "\n",
    "del article_df['Unnamed: 0']\n",
    "article_df = article_df.drop_duplicates('Title',keep = 'first')\n",
    "article_df = article_df.drop(article_df[article_df['Date'] == '2019.12.31'].index)\n",
    "article_df = article_df.dropna(axis=0)\n",
    "article_df = article_df.reset_index(drop=True)\n",
    "#print(len(article_df))\n",
    "for i in range(len(article_df)):\n",
    "    #print(i)\n",
    "    article_df['Date'][i] = article_df['Date'][i].replace('.','-')\n",
    "article_df = article_df.sort_values('Date')\n",
    "\n",
    "\n",
    "while True:\n",
    "    index = article_df['Date'].isin(date_df['Date']) == False\n",
    "    holidays = article_df['Date'][index]\n",
    "    #print(len(holidays))\n",
    "    if len(holidays) == 0:\n",
    "        break\n",
    "    else:\n",
    "        for i in range(len(holidays)):\n",
    "            holiday = holidays.iloc[i]\n",
    "            conv_hd = datetime.datetime.strptime(holiday,'%Y-%m-%d')\n",
    "            not_holiday = str(conv_hd + datetime.timedelta(days=1))[:10]\n",
    "            holidays.iloc[i] = not_holiday\n",
    "        article_df['Date'][index] = holidays \n",
    "\n",
    "merge_df = pd.merge(date_df, article_df, left_on=['Date','Category'], right_on=['Date','Category'], how='left')\n",
    "\n",
    "# one-hot encoding\n",
    "merge_df['politics']=0\n",
    "merge_df['economics']=0\n",
    "merge_df['IT']=0\n",
    "merge_df['finance']=0\n",
    "merge_df['realEstate']=0\n",
    "merge_df['international']=0\n",
    "merge_df['social']=0\n",
    "merge_df['life']=0\n",
    "merge_df['golf']=0\n",
    "merge_df['ent']=0\n",
    "\n",
    "for i in range(len(merge_df)):\n",
    "    if merge_df['Category'][i] == 2:\n",
    "        merge_df['politics'][i] = 1\n",
    "    elif merge_df['Category'][i] == 3:\n",
    "        merge_df['economics'][i] = 1\n",
    "    elif merge_df['Category'][i] == 4:\n",
    "        merge_df['IT'][i] = 1\n",
    "    elif merge_df['Category'][i] == 5:\n",
    "        merge_df['finance'][i] = 1\n",
    "    elif merge_df['Category'][i] == 6:\n",
    "        merge_df['realEstate'][i] = 1\n",
    "    elif merge_df['Category'][i] == 7:\n",
    "        merge_df['international'][i] = 1\n",
    "    elif merge_df['Category'][i] == 8:\n",
    "        merge_df['social'][i] = 1\n",
    "    elif merge_df['Category'][i] == 9:\n",
    "        merge_df['life'][i] = 1\n",
    "    elif merge_df['Category'][i] == 10:\n",
    "        merge_df['golf'][i] = 1\n",
    "    elif merge_df['Category'][i] == 11:\n",
    "        merge_df['ent'][i] = 1\n",
    "    #print(i)\n",
    "\n",
    "del merge_df['Category']    \n",
    "merge_df.to_csv('cj_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv('cj_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>label</th>\n",
       "      <th>politics</th>\n",
       "      <th>economics</th>\n",
       "      <th>IT</th>\n",
       "      <th>finance</th>\n",
       "      <th>realEstate</th>\n",
       "      <th>international</th>\n",
       "      <th>social</th>\n",
       "      <th>life</th>\n",
       "      <th>golf</th>\n",
       "      <th>ent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15488</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15489</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15490</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15491</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15492</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15493 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date Title label  politics  economics  IT  finance  realEstate  \\\n",
       "0      2014-01-02   NaN   NaN         1          0   0        0           0   \n",
       "1      2014-01-02   NaN   NaN         0          1   0        0           0   \n",
       "2      2014-01-02   NaN   NaN         0          0   1        0           0   \n",
       "3      2014-01-02   NaN   NaN         0          0   0        1           0   \n",
       "4      2014-01-02   NaN   NaN         0          0   0        0           1   \n",
       "...           ...   ...   ...       ...        ...  ..      ...         ...   \n",
       "15488  2019-12-30   NaN   NaN         0          0   0        0           0   \n",
       "15489  2019-12-30   NaN   NaN         0          0   0        0           0   \n",
       "15490  2019-12-30   NaN   NaN         0          0   0        0           0   \n",
       "15491  2019-12-30   NaN   NaN         0          0   0        0           0   \n",
       "15492  2019-12-30   NaN   NaN         0          0   0        0           0   \n",
       "\n",
       "       international  social  life  golf  ent  \n",
       "0                  0       0     0     0    0  \n",
       "1                  0       0     0     0    0  \n",
       "2                  0       0     0     0    0  \n",
       "3                  0       0     0     0    0  \n",
       "4                  0       0     0     0    0  \n",
       "...              ...     ...   ...   ...  ...  \n",
       "15488              1       0     0     0    0  \n",
       "15489              0       1     0     0    0  \n",
       "15490              0       0     1     0    0  \n",
       "15491              0       0     0     1    0  \n",
       "15492              0       0     0     0    1  \n",
       "\n",
       "[15493 rows x 13 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "del a['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>label</th>\n",
       "      <th>politics</th>\n",
       "      <th>economics</th>\n",
       "      <th>IT</th>\n",
       "      <th>finance</th>\n",
       "      <th>realEstate</th>\n",
       "      <th>international</th>\n",
       "      <th>social</th>\n",
       "      <th>life</th>\n",
       "      <th>golf</th>\n",
       "      <th>ent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15488</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15489</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15490</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15491</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15492</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15493 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date label  politics  economics  IT  finance  realEstate  \\\n",
       "0      2014-01-02   NaN         1          0   0        0           0   \n",
       "1      2014-01-02   NaN         0          1   0        0           0   \n",
       "2      2014-01-02   NaN         0          0   1        0           0   \n",
       "3      2014-01-02   NaN         0          0   0        1           0   \n",
       "4      2014-01-02   NaN         0          0   0        0           1   \n",
       "...           ...   ...       ...        ...  ..      ...         ...   \n",
       "15488  2019-12-30   NaN         0          0   0        0           0   \n",
       "15489  2019-12-30   NaN         0          0   0        0           0   \n",
       "15490  2019-12-30   NaN         0          0   0        0           0   \n",
       "15491  2019-12-30   NaN         0          0   0        0           0   \n",
       "15492  2019-12-30   NaN         0          0   0        0           0   \n",
       "\n",
       "       international  social  life  golf  ent  \n",
       "0                  0       0     0     0    0  \n",
       "1                  0       0     0     0    0  \n",
       "2                  0       0     0     0    0  \n",
       "3                  0       0     0     0    0  \n",
       "4                  0       0     0     0    0  \n",
       "...              ...     ...   ...   ...  ...  \n",
       "15488              1       0     0     0    0  \n",
       "15489              0       1     0     0    0  \n",
       "15490              0       0     1     0    0  \n",
       "15491              0       0     0     1    0  \n",
       "15492              0       0     0     0    1  \n",
       "\n",
       "[15493 rows x 12 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 날짜가 같고카테고리가 같다면 긍정 부정 중립으로 합친다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 긍정일때 3, 부정일때 1, 중립일때 2로 변경\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
