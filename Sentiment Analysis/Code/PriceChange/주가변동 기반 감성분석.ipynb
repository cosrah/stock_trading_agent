{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, LSTM\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기\n",
    "\n",
    "- 주가변동률에 따라 긍부정도를 labeling한 GS건설, KB금융, 아모레퍼시픽, 삼성전자, 이마트 데이터 셋을 이용하여 훈련\n",
    "\n",
    "- 순서\n",
    "    1. 데이터 불러오기\n",
    "    2. 데이터 분리\n",
    "    3. Title 의 토큰화 및 불용어 제거\n",
    "    4. Label 의 원핫인코딩\n",
    "    5. 길이가 다른 title의 정형화\n",
    "    6. LSTM을 통한 딥러닝\n",
    "    7. 정확도 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 구성\n",
    "- Train Dataset : kospis 2000개 합친 데이터의 80%\n",
    "- Test Dataset : kospis 2000개 합친 데이터의 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 종목별 2000개 데이터 추출하여 train dataframe 만들기\n",
    "\n",
    "kospis = ['GS건설','KB금융','아모레퍼시픽','삼성전자','이마트'] \n",
    "train_df = pd.DataFrame(columns = ['Date', 'Category', 'Title', 'Label'])\n",
    "\n",
    "for kospi in kospis:\n",
    "    temp_df = pd.read_csv('../../Data/PriceChange/{}_roc_traindata.csv'.format(kospi))\n",
    "    temp_df = shuffle(temp_df)\n",
    "    train_df = train_df.append(temp_df[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.Title\n",
    "y = train_df.Label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 제거 및 단어 분리\n",
    "stopwords = ['의', '가', '이', '은', '들', '는', '좀', '잘', '걍', '과', '도', '를', '으로', '자', '에', '와', '한', \\\n",
    "              '하다', '까지','…','?','.',',','!','\"',\"'\",'로','고','(',')','[',']','ㄹ까']\n",
    "\n",
    "import konlpy\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()\n",
    "X_train_token = []\n",
    "for sentence in X_train:\n",
    "    temp_X = [] \n",
    "    temp_X = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "    X_train_token.append(temp_X)\n",
    "\n",
    "X_test_token = []\n",
    "for sentence in X_test:\n",
    "    temp_X = []\n",
    "    temp_X = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "    X_test_token.append(temp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단어길이 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "max_words = 15000\n",
    "tokenizer = Tokenizer(num_words = max_words)\n",
    "tokenizer.fit_on_texts(X_train_token) \n",
    "X_train_token = tokenizer.texts_to_sequences(X_train_token) \n",
    "X_test_token = tokenizer.texts_to_sequences(X_test_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11508 11502\n"
     ]
    }
   ],
   "source": [
    "li_train = []\n",
    "for i in range(len(X_train_token)):\n",
    "   li_train.append(max(X_train_token[i]))\n",
    "\n",
    "\n",
    "li_test = []\n",
    "for i in range(len(X_test_token)):\n",
    "   li_test.append(max(X_test_token[i]))\n",
    "\n",
    "print(max(li_train), max(li_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 25\n"
     ]
    }
   ],
   "source": [
    "li_train = []\n",
    "# li_train.append(1)\n",
    "# li_train.append(2)\n",
    "for i in range(len(X_train_token)):\n",
    "   li_train.append(len(X_train_token[i]))\n",
    "\n",
    "\n",
    "li_test = []\n",
    "# li_train.append(1)\n",
    "# li_train.append(2)\n",
    "for i in range(len(X_test_token)):\n",
    "   li_test.append(len(X_test_token[i]))\n",
    "print(max(li_train), max(li_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_encode = []\n",
    "y_test_encode = []\n",
    "for i in range(len(y_train)):\n",
    "    if y_train.iloc[i] == 1:\n",
    "        y_train_encode.append([0, 1]) \n",
    "    else:\n",
    "        y_train_encode.append([1, 0]) \n",
    "        \n",
    "for i in range(len(y_test)):\n",
    "    if y_test.iloc[i] == 1:\n",
    "        y_test_encode.append([0, 1]) \n",
    "    else:\n",
    "        y_test_encode.append([1, 0]) \n",
    "        \n",
    "y_train_encode=np.array(y_train_encode)\n",
    "y_test_encode=np.array(y_test_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### max_len 20 to 100으로 변경 ; 단어 길이 고려"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 30 # pad_sequesces이용, 전체 데이터의 길이를 20로 맞춘다\n",
    "X_train = pad_sequences(X_train_token, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test_token, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 저장1\n",
    "import os\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "MODEL_DIR = './ModelCheckpoint/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "    \n",
    "mdpath = './ModelCheckpoint/{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "mc = ModelCheckpoint(filepath=mdpath,monitor='val_acc',mode='max',verbose=1,save_best_only=True)\n",
    "es = EarlyStopping(monitor='val_loss',patience=10,mode='min',verbose=1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 64))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train_cata, epochs=10, batch_size=10, callbacks=[es,mc], validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 저장2\n",
    "from keras.models import load_model\n",
    "##### 모델 컴퓨터에 저장\n",
    "model.save('모델이름')\n",
    "##### 모델 불러오기\n",
    "del model # 테스트를 위해 메모리 내의 모델을 삭제\n",
    "model = load_model('모델명')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### earlystopping과 modelcheckpoint 추가\n",
    "### embedding 64로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": " Cast string to float is not supported\n\t [[node sequential_21/Cast (defined at <ipython-input-115-6550f11d33eb>:10) ]] [Op:__inference_train_function_96753]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-115-6550f11d33eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rmsprop'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_encode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n 테스트 정확도 : {:.2f}%\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test_encode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    838\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnimplementedError\u001b[0m:  Cast string to float is not supported\n\t [[node sequential_21/Cast (defined at <ipython-input-115-6550f11d33eb>:10) ]] [Op:__inference_train_function_96753]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "es = EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=10)\n",
    "mc = ModelCheckpoint('best_model.h5',monitor='val_acc',mode='max',verbose=1,save_best_only=True)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 64))\n",
    "model.add(LSTM(128,activation='tanh'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train_encode, epochs=20, batch_size=10, callbacks=[es,mc], validation_split=0.1)\n",
    "\n",
    "print(\"\\n 테스트 정확도 : {:.2f}%\".format(model.evaluate(X_test,y_test_encode)[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000 8000\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(y_train_encode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:747 train_step\n        y_pred = self(x, training=True)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:372 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:386 call\n        inputs, training=training, mask=mask)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:508 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py:247 call\n        outputs = self._convolution_op(inputs, self.kernel)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:1018 convolution_v2\n        name=name)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:1148 convolution_internal\n        name=name)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:574 new_func\n        return func(*args, **kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:574 new_func\n        return func(*args, **kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:1889 conv1d\n        name=name)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py:979 conv2d\n        data_format=data_format, dilations=dilations, name=name)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:744 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:593 _create_op_internal\n        compute_device)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3485 _create_op_internal\n        op_def=op_def)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1975 __init__\n        control_input_ops, op_def)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1815 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Negative dimension size caused by subtracting 5 from 1 for '{{node sequential_20/conv1d_4/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](sequential_20/conv1d_4/conv1d/ExpandDims, sequential_20/conv1d_4/conv1d/ExpandDims_1)' with input shapes: [100,1,1,100], [1,5,100,64].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-114-e8dd368b4005>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mmodel6\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel6\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_encode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_encode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n 테스트 정확도 : {:.2f}%\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel6\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test_encode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    821\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 697\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2854\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2855\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2856\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3075\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:747 train_step\n        y_pred = self(x, training=True)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:372 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:386 call\n        inputs, training=training, mask=mask)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:508 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py:247 call\n        outputs = self._convolution_op(inputs, self.kernel)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:1018 convolution_v2\n        name=name)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:1148 convolution_internal\n        name=name)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:574 new_func\n        return func(*args, **kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:574 new_func\n        return func(*args, **kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:1889 conv1d\n        name=name)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py:979 conv2d\n        data_format=data_format, dilations=dilations, name=name)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:744 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:593 _create_op_internal\n        compute_device)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3485 _create_op_internal\n        op_def=op_def)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1975 __init__\n        control_input_ops, op_def)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1815 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Negative dimension size caused by subtracting 5 from 1 for '{{node sequential_20/conv1d_4/conv1d}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](sequential_20/conv1d_4/conv1d/ExpandDims, sequential_20/conv1d_4/conv1d/ExpandDims_1)' with input shapes: [100,1,1,100], [1,5,100,64].\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "\n",
    "model6 = Sequential()\n",
    "model6.add(Embedding(max_words, 100))\n",
    "model6.add(Dropout(0.5))\n",
    "model6.add(Conv1D(64, 5, padding='valid', activation='relu', strides=1))\n",
    "model6.add(MaxPooling1D(pool_size=4))\n",
    "model6.add(LSTM(55))\n",
    "model6.add(Dense(2, activation='relu'))\n",
    "\n",
    "model6.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model6.fit(X_train, y_train_encode, epochs=20, batch_size=100, callbacks=[es,mc], validation_data=(X_test, y_test_encode))\n",
    "\n",
    "print(\"\\n 테스트 정확도 : {:.2f}%\".format(model6.evaluate(X_test,y_test_encode)[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.save('M1_61.21%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFOLD 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed 값 설정\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "#tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X_train\n",
    "Y=y_train_cata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10개의 파일로 쪼갬\n",
    "n_fold = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf =KFold(n_splits=n_fold, shuffle=True,random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#빈 accuracy 배열\n",
    "accuracy =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 1.0048 - accuracy: 0.5245WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 5s 50ms/step - loss: 1.0034 - accuracy: 0.5253 - val_loss: 0.9877 - val_accuracy: 0.5439\n",
      "Epoch 2/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.9308 - accuracy: 0.5828WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 0.9308 - accuracy: 0.5828 - val_loss: 0.7731 - val_accuracy: 0.7105\n",
      "Epoch 3/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.8479 - accuracy: 0.6072WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 0.8479 - accuracy: 0.6072 - val_loss: 0.7933 - val_accuracy: 0.7281\n",
      "Epoch 4/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.8125 - accuracy: 0.6176WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 0.8140 - accuracy: 0.6170 - val_loss: 0.7442 - val_accuracy: 0.7193\n",
      "Epoch 5/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.7930 - accuracy: 0.6147WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 0.7925 - accuracy: 0.6140 - val_loss: 0.7682 - val_accuracy: 0.6930\n",
      "Epoch 6/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.7837 - accuracy: 0.6235WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 0.7822 - accuracy: 0.6248 - val_loss: 0.7500 - val_accuracy: 0.6930\n",
      "Epoch 7/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.7666 - accuracy: 0.6392WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 0.7663 - accuracy: 0.6384 - val_loss: 0.8206 - val_accuracy: 0.6667\n",
      "Epoch 8/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.7590 - accuracy: 0.6431WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 5s 47ms/step - loss: 0.7592 - accuracy: 0.6442 - val_loss: 0.8401 - val_accuracy: 0.6667\n",
      "Epoch 00008: early stopping\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8750 - accuracy: 0.6220\n",
      "Epoch 1/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 1.0024 - accuracy: 0.5265WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 57ms/step - loss: 1.0022 - accuracy: 0.5263 - val_loss: 0.9412 - val_accuracy: 0.5702\n",
      "Epoch 2/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.9105 - accuracy: 0.5750WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 7s 65ms/step - loss: 0.9105 - accuracy: 0.5750 - val_loss: 0.7091 - val_accuracy: 0.7281\n",
      "Epoch 3/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.8427 - accuracy: 0.5994WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 7s 66ms/step - loss: 0.8427 - accuracy: 0.5994 - val_loss: 0.6885 - val_accuracy: 0.7368\n",
      "Epoch 4/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.7989 - accuracy: 0.6199WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 7s 65ms/step - loss: 0.7989 - accuracy: 0.6199 - val_loss: 0.7467 - val_accuracy: 0.7281\n",
      "Epoch 5/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.7881 - accuracy: 0.6326WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 7s 64ms/step - loss: 0.7881 - accuracy: 0.6326 - val_loss: 0.7066 - val_accuracy: 0.7368\n",
      "Epoch 6/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.7711 - accuracy: 0.6257WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 7s 64ms/step - loss: 0.7711 - accuracy: 0.6257 - val_loss: 0.6905 - val_accuracy: 0.7105\n",
      "Epoch 7/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.7468 - accuracy: 0.6384WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 7s 65ms/step - loss: 0.7468 - accuracy: 0.6384 - val_loss: 0.7893 - val_accuracy: 0.7018\n",
      "Epoch 00007: early stopping\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.0404 - accuracy: 0.6341\n",
      "Epoch 1/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 1.0099 - accuracy: 0.5263WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 59ms/step - loss: 1.0099 - accuracy: 0.5263 - val_loss: 1.0036 - val_accuracy: 0.5526\n",
      "Epoch 2/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.9123 - accuracy: 0.5647WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 57ms/step - loss: 0.9131 - accuracy: 0.5653 - val_loss: 0.7531 - val_accuracy: 0.7368\n",
      "Epoch 3/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.8355 - accuracy: 0.6069WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 57ms/step - loss: 0.8372 - accuracy: 0.6062 - val_loss: 0.7514 - val_accuracy: 0.6754\n",
      "Epoch 4/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.7994 - accuracy: 0.6186WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 56ms/step - loss: 0.8035 - accuracy: 0.6170 - val_loss: 0.7208 - val_accuracy: 0.6754\n",
      "Epoch 5/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.7848 - accuracy: 0.6333WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 56ms/step - loss: 0.7830 - accuracy: 0.6355 - val_loss: 0.7888 - val_accuracy: 0.6579\n",
      "Epoch 6/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.7714 - accuracy: 0.6196WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 56ms/step - loss: 0.7703 - accuracy: 0.6209 - val_loss: 0.7687 - val_accuracy: 0.6667\n",
      "Epoch 7/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.7552 - accuracy: 0.6392WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 56ms/step - loss: 0.7533 - accuracy: 0.6413 - val_loss: 0.8618 - val_accuracy: 0.6140\n",
      "Epoch 8/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.9368 - accuracy: 0.5814WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 56ms/step - loss: 0.9370 - accuracy: 0.5819 - val_loss: 1.0824 - val_accuracy: 0.4737\n",
      "Epoch 00008: early stopping\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9317 - accuracy: 0.5244\n",
      "Epoch 1/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 1.0089 - accuracy: 0.5283WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 61ms/step - loss: 1.0089 - accuracy: 0.5283 - val_loss: 0.9597 - val_accuracy: 0.5614\n",
      "Epoch 2/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.9122 - accuracy: 0.5588WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 57ms/step - loss: 0.9133 - accuracy: 0.5585 - val_loss: 0.7752 - val_accuracy: 0.6930\n",
      "Epoch 3/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.8337 - accuracy: 0.6023WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 58ms/step - loss: 0.8337 - accuracy: 0.6023 - val_loss: 0.7777 - val_accuracy: 0.7368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.8060 - accuracy: 0.6176WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 56ms/step - loss: 0.8074 - accuracy: 0.6160 - val_loss: 0.7603 - val_accuracy: 0.7105\n",
      "Epoch 5/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.7856 - accuracy: 0.6284WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 55ms/step - loss: 0.7865 - accuracy: 0.6257 - val_loss: 0.7794 - val_accuracy: 0.6930\n",
      "Epoch 6/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.7741 - accuracy: 0.6402WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 55ms/step - loss: 0.7737 - accuracy: 0.6404 - val_loss: 0.8266 - val_accuracy: 0.7018\n",
      "Epoch 7/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.7608 - accuracy: 0.6431WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 54ms/step - loss: 0.7617 - accuracy: 0.6433 - val_loss: 0.8009 - val_accuracy: 0.7018\n",
      "Epoch 8/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.7547 - accuracy: 0.6461WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 54ms/step - loss: 0.7571 - accuracy: 0.6452 - val_loss: 0.8409 - val_accuracy: 0.6579\n",
      "Epoch 00008: early stopping\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9072 - accuracy: 0.5610\n",
      "Epoch 1/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 1.0027 - accuracy: 0.5284WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 5s 52ms/step - loss: 1.0028 - accuracy: 0.5292 - val_loss: 0.9903 - val_accuracy: 0.5614\n",
      "Epoch 2/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.9044 - accuracy: 0.5578WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 5s 51ms/step - loss: 0.9029 - accuracy: 0.5595 - val_loss: 0.7803 - val_accuracy: 0.6754\n",
      "Epoch 3/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.8443 - accuracy: 0.6049WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 5s 52ms/step - loss: 0.8427 - accuracy: 0.6072 - val_loss: 0.7471 - val_accuracy: 0.7105\n",
      "Epoch 4/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.8087 - accuracy: 0.6345WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 5s 52ms/step - loss: 0.8087 - accuracy: 0.6345 - val_loss: 0.8116 - val_accuracy: 0.6579\n",
      "Epoch 5/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.7931 - accuracy: 0.6206WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 5s 52ms/step - loss: 0.7933 - accuracy: 0.6199 - val_loss: 0.7976 - val_accuracy: 0.6579\n",
      "Epoch 6/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.7784 - accuracy: 0.6412WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 5s 52ms/step - loss: 0.7772 - accuracy: 0.6423 - val_loss: 0.8084 - val_accuracy: 0.6579\n",
      "Epoch 7/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.9236 - accuracy: 0.6069WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 5s 52ms/step - loss: 0.9235 - accuracy: 0.6062 - val_loss: 0.9248 - val_accuracy: 0.5175\n",
      "Epoch 00007: early stopping\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9319 - accuracy: 0.5366\n",
      "Epoch 1/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 1.0033 - accuracy: 0.5302WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 7s 67ms/step - loss: 1.0033 - accuracy: 0.5302 - val_loss: 1.0057 - val_accuracy: 0.5351\n",
      "Epoch 2/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.9094 - accuracy: 0.5663WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 7s 65ms/step - loss: 0.9094 - accuracy: 0.5663 - val_loss: 0.7587 - val_accuracy: 0.7281\n",
      "Epoch 3/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.8341 - accuracy: 0.6072WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 7s 65ms/step - loss: 0.8341 - accuracy: 0.6072 - val_loss: 0.7311 - val_accuracy: 0.7018\n",
      "Epoch 4/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.8003 - accuracy: 0.6248WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 7s 65ms/step - loss: 0.8003 - accuracy: 0.6248 - val_loss: 0.7982 - val_accuracy: 0.6930\n",
      "Epoch 5/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.7830 - accuracy: 0.6335WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 7s 65ms/step - loss: 0.7830 - accuracy: 0.6335 - val_loss: 0.7635 - val_accuracy: 0.6842\n",
      "Epoch 6/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.7612 - accuracy: 0.6355WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 7s 66ms/step - loss: 0.7612 - accuracy: 0.6355 - val_loss: 0.8154 - val_accuracy: 0.6579\n",
      "Epoch 7/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.7488 - accuracy: 0.6442WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 7s 65ms/step - loss: 0.7488 - accuracy: 0.6442 - val_loss: 0.8005 - val_accuracy: 0.6842\n",
      "Epoch 00007: early stopping\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.8671 - accuracy: 0.5122\n",
      "Epoch 1/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 1.0106 - accuracy: 0.5097WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 7s 67ms/step - loss: 1.0106 - accuracy: 0.5097 - val_loss: 0.9756 - val_accuracy: 0.5614\n",
      "Epoch 2/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.8964 - accuracy: 0.5750WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 7s 68ms/step - loss: 0.8964 - accuracy: 0.5750 - val_loss: 0.7866 - val_accuracy: 0.6754\n",
      "Epoch 3/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.8409 - accuracy: 0.6092WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 7s 66ms/step - loss: 0.8409 - accuracy: 0.6092 - val_loss: 0.7615 - val_accuracy: 0.7018\n",
      "Epoch 4/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.8034 - accuracy: 0.6335WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 7s 67ms/step - loss: 0.8034 - accuracy: 0.6335 - val_loss: 0.7825 - val_accuracy: 0.6754\n",
      "Epoch 5/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.7840 - accuracy: 0.6170WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 7s 68ms/step - loss: 0.7840 - accuracy: 0.6170 - val_loss: 0.7544 - val_accuracy: 0.6930\n",
      "Epoch 6/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.7751 - accuracy: 0.6296WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 7s 68ms/step - loss: 0.7751 - accuracy: 0.6296 - val_loss: 0.7799 - val_accuracy: 0.6754\n",
      "Epoch 7/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.7626 - accuracy: 0.6394WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 7s 68ms/step - loss: 0.7626 - accuracy: 0.6394 - val_loss: 0.7672 - val_accuracy: 0.6930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.7404 - accuracy: 0.6394WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 7s 67ms/step - loss: 0.7404 - accuracy: 0.6394 - val_loss: 0.8264 - val_accuracy: 0.6667\n",
      "Epoch 9/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.7324 - accuracy: 0.6686WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 7s 67ms/step - loss: 0.7324 - accuracy: 0.6686 - val_loss: 0.8056 - val_accuracy: 0.6842\n",
      "Epoch 00009: early stopping\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9027 - accuracy: 0.5488\n",
      "Epoch 1/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 1.0134 - accuracy: 0.5343WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 61ms/step - loss: 1.0142 - accuracy: 0.5341 - val_loss: 0.9939 - val_accuracy: 0.5304\n",
      "Epoch 2/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.9075 - accuracy: 0.5549WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 57ms/step - loss: 0.9069 - accuracy: 0.5556 - val_loss: 0.8102 - val_accuracy: 0.7304\n",
      "Epoch 3/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.8423 - accuracy: 0.5941WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 57ms/step - loss: 0.8412 - accuracy: 0.5955 - val_loss: 0.7479 - val_accuracy: 0.6609\n",
      "Epoch 4/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.8075 - accuracy: 0.6245WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 57ms/step - loss: 0.8065 - accuracy: 0.6248 - val_loss: 0.7515 - val_accuracy: 0.6870\n",
      "Epoch 5/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.7869 - accuracy: 0.6157WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 57ms/step - loss: 0.7855 - accuracy: 0.6170 - val_loss: 0.7426 - val_accuracy: 0.6696\n",
      "Epoch 6/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.7699 - accuracy: 0.6343WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 57ms/step - loss: 0.7707 - accuracy: 0.6345 - val_loss: 0.7384 - val_accuracy: 0.6957\n",
      "Epoch 7/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.7613 - accuracy: 0.6324WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 59ms/step - loss: 0.7607 - accuracy: 0.6316 - val_loss: 0.7855 - val_accuracy: 0.6609\n",
      "Epoch 8/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.7448 - accuracy: 0.6404WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 7s 63ms/step - loss: 0.7448 - accuracy: 0.6404 - val_loss: 0.8024 - val_accuracy: 0.6783\n",
      "Epoch 9/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.7346 - accuracy: 0.6559WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 60ms/step - loss: 0.7346 - accuracy: 0.6559 - val_loss: 0.8619 - val_accuracy: 0.6261\n",
      "Epoch 10/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.7374 - accuracy: 0.6608WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 7s 65ms/step - loss: 0.7374 - accuracy: 0.6608 - val_loss: 0.8148 - val_accuracy: 0.6609\n",
      "Epoch 00010: early stopping\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8967 - accuracy: 0.5679\n",
      "Epoch 1/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 1.0070 - accuracy: 0.5292WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 7s 65ms/step - loss: 1.0070 - accuracy: 0.5292 - val_loss: 0.9785 - val_accuracy: 0.5478\n",
      "Epoch 2/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.8891 - accuracy: 0.5716WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 62ms/step - loss: 0.8891 - accuracy: 0.5721 - val_loss: 0.7729 - val_accuracy: 0.7478\n",
      "Epoch 3/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.8346 - accuracy: 0.6072WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 8s 73ms/step - loss: 0.8346 - accuracy: 0.6072 - val_loss: 0.7501 - val_accuracy: 0.6957\n",
      "Epoch 4/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.7971 - accuracy: 0.6277WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 7s 65ms/step - loss: 0.7971 - accuracy: 0.6277 - val_loss: 0.7553 - val_accuracy: 0.7043\n",
      "Epoch 5/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.7724 - accuracy: 0.6402WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 61ms/step - loss: 0.7718 - accuracy: 0.6413 - val_loss: 0.7378 - val_accuracy: 0.7391\n",
      "Epoch 6/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.7616 - accuracy: 0.6422WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 61ms/step - loss: 0.7642 - accuracy: 0.6404 - val_loss: 0.7370 - val_accuracy: 0.7043\n",
      "Epoch 7/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.7575 - accuracy: 0.6314WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 61ms/step - loss: 0.7558 - accuracy: 0.6326 - val_loss: 0.7450 - val_accuracy: 0.7043\n",
      "Epoch 8/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.7383 - accuracy: 0.6511WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 61ms/step - loss: 0.7383 - accuracy: 0.6511 - val_loss: 0.7740 - val_accuracy: 0.6870\n",
      "Epoch 9/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.7319 - accuracy: 0.6637WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 60ms/step - loss: 0.7329 - accuracy: 0.6628 - val_loss: 0.8075 - val_accuracy: 0.7043\n",
      "Epoch 10/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.7240 - accuracy: 0.6676WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 60ms/step - loss: 0.7243 - accuracy: 0.6676 - val_loss: 0.7872 - val_accuracy: 0.6783\n",
      "Epoch 00010: early stopping\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.0874 - accuracy: 0.5062\n",
      "Epoch 1/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 1.0006 - accuracy: 0.5304WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 60ms/step - loss: 1.0021 - accuracy: 0.5283 - val_loss: 0.9712 - val_accuracy: 0.5478\n",
      "Epoch 2/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.9030 - accuracy: 0.5716WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 58ms/step - loss: 0.9035 - accuracy: 0.5702 - val_loss: 0.7766 - val_accuracy: 0.7391\n",
      "Epoch 3/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.8350 - accuracy: 0.6039WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 59ms/step - loss: 0.8354 - accuracy: 0.6043 - val_loss: 0.7388 - val_accuracy: 0.7217\n",
      "Epoch 4/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.8023 - accuracy: 0.6196WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 59ms/step - loss: 0.8040 - accuracy: 0.6179 - val_loss: 0.7319 - val_accuracy: 0.7391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.7847 - accuracy: 0.6353WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 59ms/step - loss: 0.7827 - accuracy: 0.6365 - val_loss: 0.7314 - val_accuracy: 0.7217\n",
      "Epoch 6/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.7905 - accuracy: 0.6394 EWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 59ms/step - loss: 0.7905 - accuracy: 0.6394 - val_loss: 0.8992 - val_accuracy: 0.5478\n",
      "Epoch 7/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.7930 - accuracy: 0.6235WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 59ms/step - loss: 0.7934 - accuracy: 0.6218 - val_loss: 0.7652 - val_accuracy: 0.6696\n",
      "Epoch 8/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.7461 - accuracy: 0.6549WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 60ms/step - loss: 0.7446 - accuracy: 0.6559 - val_loss: 0.7676 - val_accuracy: 0.7043\n",
      "Epoch 9/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.7342 - accuracy: 0.6598WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 60ms/step - loss: 0.7324 - accuracy: 0.6618 - val_loss: 0.8271 - val_accuracy: 0.6609\n",
      "Epoch 00009: early stopping\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9885 - accuracy: 0.5926\n",
      "Epoch 1/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 1.0028 - accuracy: 0.5263WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 61ms/step - loss: 1.0028 - accuracy: 0.5263 - val_loss: 0.9828 - val_accuracy: 0.5391\n",
      "Epoch 2/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.9079 - accuracy: 0.5716WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 58ms/step - loss: 0.9092 - accuracy: 0.5702 - val_loss: 0.7750 - val_accuracy: 0.6957\n",
      "Epoch 3/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.8386 - accuracy: 0.6127WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 58ms/step - loss: 0.8394 - accuracy: 0.6111 - val_loss: 0.7006 - val_accuracy: 0.7130\n",
      "Epoch 4/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.8024 - accuracy: 0.6333WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 57ms/step - loss: 0.8016 - accuracy: 0.6355 - val_loss: 0.7277 - val_accuracy: 0.7043\n",
      "Epoch 5/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.7802 - accuracy: 0.6363WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 58ms/step - loss: 0.7832 - accuracy: 0.6355 - val_loss: 0.7375 - val_accuracy: 0.7130\n",
      "Epoch 6/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.7809 - accuracy: 0.6294WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 58ms/step - loss: 0.7811 - accuracy: 0.6296 - val_loss: 0.7346 - val_accuracy: 0.6783\n",
      "Epoch 7/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.7633 - accuracy: 0.6324WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 58ms/step - loss: 0.7613 - accuracy: 0.6345 - val_loss: 0.7572 - val_accuracy: 0.6783\n",
      "Epoch 00007: early stopping\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8135 - accuracy: 0.5679\n",
      "Epoch 1/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 1.0100 - accuracy: 0.5273WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 60ms/step - loss: 1.0100 - accuracy: 0.5273 - val_loss: 1.0147 - val_accuracy: 0.5391\n",
      "Epoch 2/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.9103 - accuracy: 0.5556 ETA: 0s - lWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 61ms/step - loss: 0.9103 - accuracy: 0.5556 - val_loss: 0.8118 - val_accuracy: 0.6696\n",
      "Epoch 3/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.8278 - accuracy: 0.6157WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 61ms/step - loss: 0.8268 - accuracy: 0.6160 - val_loss: 0.7690 - val_accuracy: 0.6783\n",
      "Epoch 4/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.7873 - accuracy: 0.6267WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 61ms/step - loss: 0.7873 - accuracy: 0.6267 - val_loss: 0.8613 - val_accuracy: 0.6609\n",
      "Epoch 5/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.7784 - accuracy: 0.6265 ETA: 3s - l - ETA: 1s -WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 61ms/step - loss: 0.7767 - accuracy: 0.6277 - val_loss: 0.8168 - val_accuracy: 0.6522\n",
      "Epoch 6/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.7569 - accuracy: 0.6363WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 61ms/step - loss: 0.7578 - accuracy: 0.6345 - val_loss: 0.8891 - val_accuracy: 0.6435\n",
      "Epoch 7/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.7521 - accuracy: 0.6520WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 62ms/step - loss: 0.7531 - accuracy: 0.6501 - val_loss: 0.8749 - val_accuracy: 0.6522\n",
      "Epoch 00007: early stopping\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.9531 - accuracy: 0.6049\n",
      "Epoch 1/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 1.0136 - accuracy: 0.5312WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 7s 63ms/step - loss: 1.0136 - accuracy: 0.5312 - val_loss: 1.0179 - val_accuracy: 0.5391\n",
      "Epoch 2/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.9210 - accuracy: 0.5575WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 61ms/step - loss: 0.9210 - accuracy: 0.5575 - val_loss: 0.8064 - val_accuracy: 0.6957\n",
      "Epoch 3/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.8360 - accuracy: 0.6255WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 61ms/step - loss: 0.8359 - accuracy: 0.6248 - val_loss: 0.7593 - val_accuracy: 0.6957\n",
      "Epoch 4/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.8011 - accuracy: 0.6353WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 62ms/step - loss: 0.8060 - accuracy: 0.6326 - val_loss: 0.7521 - val_accuracy: 0.6957\n",
      "Epoch 5/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.7804 - accuracy: 0.6287WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 7s 66ms/step - loss: 0.7804 - accuracy: 0.6287 - val_loss: 0.7486 - val_accuracy: 0.6783\n",
      "Epoch 6/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.7712 - accuracy: 0.6442WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 62ms/step - loss: 0.7712 - accuracy: 0.6442 - val_loss: 0.8234 - val_accuracy: 0.6522\n",
      "Epoch 7/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.7575 - accuracy: 0.6365WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 63ms/step - loss: 0.7575 - accuracy: 0.6365 - val_loss: 0.8274 - val_accuracy: 0.6957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.7409 - accuracy: 0.6481WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 63ms/step - loss: 0.7409 - accuracy: 0.6481 - val_loss: 0.8573 - val_accuracy: 0.6435\n",
      "Epoch 9/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.7314 - accuracy: 0.6452WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 62ms/step - loss: 0.7314 - accuracy: 0.6452 - val_loss: 0.8596 - val_accuracy: 0.6435\n",
      "Epoch 00009: early stopping\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.8672 - accuracy: 0.6420\n",
      "Epoch 1/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 1.0030 - accuracy: 0.5304WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 63ms/step - loss: 1.0031 - accuracy: 0.5302 - val_loss: 0.9898 - val_accuracy: 0.5826\n",
      "Epoch 2/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.9021 - accuracy: 0.5735WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 61ms/step - loss: 0.9033 - accuracy: 0.5702 - val_loss: 0.7544 - val_accuracy: 0.7217\n",
      "Epoch 3/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.8489 - accuracy: 0.5863WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 60ms/step - loss: 0.8485 - accuracy: 0.5877 - val_loss: 0.7119 - val_accuracy: 0.7043\n",
      "Epoch 4/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.8139 - accuracy: 0.6069 ETA: 0s - loss: 0.8WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 60ms/step - loss: 0.8148 - accuracy: 0.6062 - val_loss: 0.7884 - val_accuracy: 0.6696\n",
      "Epoch 5/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.7840 - accuracy: 0.6294 ETA: 0s - loss: 0.7843 - accuracy: 0.WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 60ms/step - loss: 0.7863 - accuracy: 0.6277 - val_loss: 0.8434 - val_accuracy: 0.6435\n",
      "Epoch 6/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.7687 - accuracy: 0.6265WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 59ms/step - loss: 0.7704 - accuracy: 0.6257 - val_loss: 0.8018 - val_accuracy: 0.6783\n",
      "Epoch 7/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.7598 - accuracy: 0.6382WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 59ms/step - loss: 0.7602 - accuracy: 0.6374 - val_loss: 0.8286 - val_accuracy: 0.6348\n",
      "Epoch 00007: early stopping\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.8598 - accuracy: 0.6420\n",
      "Epoch 1/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 1.0025 - accuracy: 0.5331WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 60ms/step - loss: 1.0025 - accuracy: 0.5331 - val_loss: 0.9508 - val_accuracy: 0.5826\n",
      "Epoch 2/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.9057 - accuracy: 0.5824WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 58ms/step - loss: 0.9050 - accuracy: 0.5838 - val_loss: 0.7999 - val_accuracy: 0.7217\n",
      "Epoch 3/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.8304 - accuracy: 0.6127WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 59ms/step - loss: 0.8284 - accuracy: 0.6131 - val_loss: 0.7057 - val_accuracy: 0.7130\n",
      "Epoch 4/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.7905 - accuracy: 0.6275WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 59ms/step - loss: 0.7915 - accuracy: 0.6267 - val_loss: 0.8172 - val_accuracy: 0.6870\n",
      "Epoch 5/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.7925 - accuracy: 0.6255WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 59ms/step - loss: 0.7926 - accuracy: 0.6257 - val_loss: 0.7692 - val_accuracy: 0.6870\n",
      "Epoch 6/10\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.7703 - accuracy: 0.6402WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 59ms/step - loss: 0.7722 - accuracy: 0.6404 - val_loss: 0.7262 - val_accuracy: 0.7043\n",
      "Epoch 7/10\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.7546 - accuracy: 0.6569WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "103/103 [==============================] - 6s 60ms/step - loss: 0.7546 - accuracy: 0.6569 - val_loss: 0.8367 - val_accuracy: 0.6783\n",
      "Epoch 00007: early stopping\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.9911 - accuracy: 0.4691\n"
     ]
    }
   ],
   "source": [
    "#모델의 설정, 컴파일, 실행\n",
    "for train, test in skf.split(X,Y):\n",
    "    from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "    es = EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=4)\n",
    "    mc = ModelCheckpoint('best_model.h5',monitor='val_acc',mode='max',verbose=1,save_best_only=True)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_words, 64))\n",
    "    model.add(LSTM(128,activation='tanh'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(X[train],Y[train], epochs=10, batch_size=10, callbacks=[es,mc], validation_split=0.1)\n",
    "    k_accuracy = '%.4f'%(model.evaluate(X[test],Y[test])[1])\n",
    "    accuracy.append(k_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 19ms/step - loss: 0.9478 - accuracy: 0.5836\n",
      "\n",
      " 테스트 정확도 : 58.36%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n 테스트 정확도 : {:.2f}%\".format(model.evaluate(X_test,y_test_cata)[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "720/720 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5069WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "720/720 [==============================] - 13s 18ms/step - loss: 0.6926 - accuracy: 0.5069 - val_loss: 0.6929 - val_accuracy: 0.5113\n",
      "Epoch 2/20\n",
      "719/720 [============================>.] - ETA: 0s - loss: 0.6024 - accuracy: 0.6854WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "720/720 [==============================] - 13s 18ms/step - loss: 0.6025 - accuracy: 0.6853 - val_loss: 0.7464 - val_accuracy: 0.5200\n",
      "Epoch 3/20\n",
      "720/720 [==============================] - ETA: 0s - loss: 0.3625 - accuracy: 0.8413WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "720/720 [==============================] - 13s 18ms/step - loss: 0.3625 - accuracy: 0.8413 - val_loss: 0.9289 - val_accuracy: 0.5263\n",
      "Epoch 4/20\n",
      "720/720 [==============================] - ETA: 0s - loss: 0.1781 - accuracy: 0.9317WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "720/720 [==============================] - 13s 19ms/step - loss: 0.1781 - accuracy: 0.9317 - val_loss: 1.3318 - val_accuracy: 0.5200\n",
      "Epoch 5/20\n",
      "719/720 [============================>.] - ETA: 0s - loss: 0.1021 - accuracy: 0.9630WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "720/720 [==============================] - 13s 18ms/step - loss: 0.1022 - accuracy: 0.9629 - val_loss: 1.4832 - val_accuracy: 0.5387\n",
      "Epoch 6/20\n",
      "720/720 [==============================] - ETA: 0s - loss: 0.0691 - accuracy: 0.9726WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "720/720 [==============================] - 13s 18ms/step - loss: 0.0691 - accuracy: 0.9726 - val_loss: 1.9646 - val_accuracy: 0.5200\n",
      "Epoch 7/20\n",
      "719/720 [============================>.] - ETA: 0s - loss: 0.0501 - accuracy: 0.9800WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "720/720 [==============================] - 13s 18ms/step - loss: 0.0501 - accuracy: 0.9799 - val_loss: 2.4285 - val_accuracy: 0.5213\n",
      "Epoch 8/20\n",
      "718/720 [============================>.] - ETA: 0s - loss: 0.0412 - accuracy: 0.9829WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "720/720 [==============================] - 13s 18ms/step - loss: 0.0411 - accuracy: 0.9829 - val_loss: 2.4850 - val_accuracy: 0.5487\n",
      "Epoch 9/20\n",
      "718/720 [============================>.] - ETA: 0s - loss: 0.0355 - accuracy: 0.9834WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "720/720 [==============================] - 13s 18ms/step - loss: 0.0355 - accuracy: 0.9835 - val_loss: 2.5519 - val_accuracy: 0.5550\n",
      "Epoch 10/20\n",
      "718/720 [============================>.] - ETA: 0s - loss: 0.0315 - accuracy: 0.9862WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "720/720 [==============================] - 13s 18ms/step - loss: 0.0314 - accuracy: 0.9862 - val_loss: 2.8581 - val_accuracy: 0.5512\n",
      "Epoch 11/20\n",
      "718/720 [============================>.] - ETA: 0s - loss: 0.0300 - accuracy: 0.9876WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "720/720 [==============================] - 13s 18ms/step - loss: 0.0301 - accuracy: 0.9875 - val_loss: 2.7592 - val_accuracy: 0.5362\n",
      "Epoch 00011: early stopping\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 2.7893 - accuracy: 0.5180\n",
      "\n",
      " 테스트 정확도 : 51.80%\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=10)\n",
    "mc = ModelCheckpoint('best_model.h5',monitor='val_acc',mode='max',verbose=1,save_best_only=True)\n",
    "opt ='adam'\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 64))\n",
    "model.add(LSTM(128,activation='tanh'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train_encode, epochs=20, batch_size=10, callbacks=[es,mc], validation_split=0.1)\n",
    "    \n",
    "print(\"\\n 테스트 정확도 : {:.2f}%\".format(model.evaluate(X_test,y_test_encode)[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:749 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:149 __call__\n        losses = ag_call(y_true, y_pred)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:253 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1605 binary_crossentropy\n        K.binary_crossentropy(y_true, y_pred, from_logits=from_logits), axis=-1)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4823 binary_crossentropy\n        return nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:174 sigmoid_cross_entropy_with_logits\n        (logits.get_shape(), labels.get_shape()))\n\n    ValueError: logits and labels must have the same shape ((10, 1) vs (10, 2))\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-6a4aba1e4d59>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m              ,metrics=['accuracy'])\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_encode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n 테스트 정확도 : {:.2f}%\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test_encode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m# hist = model.fit(train_x,train_y,epochs=300,batch_size=500, validation_data=(test_x, test_y), verbose = 2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    821\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 697\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2854\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2855\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2856\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3075\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:749 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:149 __call__\n        losses = ag_call(y_true, y_pred)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:253 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1605 binary_crossentropy\n        K.binary_crossentropy(y_true, y_pred, from_logits=from_logits), axis=-1)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4823 binary_crossentropy\n        return nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:174 sigmoid_cross_entropy_with_logits\n        (logits.get_shape(), labels.get_shape()))\n\n    ValueError: logits and labels must have the same shape ((10, 1) vs (10, 2))\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "\n",
    "model2=models.Sequential()\n",
    "\n",
    "model2.add(layers.Dense(100, activation='relu'))\n",
    "model2.add(layers.Dense(80, activation='relu'))\n",
    "model2.add(layers.Dense(60, activation='relu'))\n",
    "model2.add(layers.Dense(40, activation='relu'))\n",
    "model2.add(layers.Dense(20, activation='relu'))\n",
    "\n",
    "model2.add(layers.Dense(10, activation='relu'))\n",
    "model2.add(layers.Dense(1,activation='sigmoid'))\n",
    "\n",
    "\n",
    "model2.compile(optimizer=optimizers.RMSprop(lr=0.0001)\n",
    "             ,loss=losses.binary_crossentropy\n",
    "             ,metrics=['accuracy'])\n",
    "\n",
    "history = model2.fit(X_train, y_train_encode, epochs=300, batch_size=10, callbacks=[es,mc], validation_split=0.1)\n",
    "print(\"\\n 테스트 정확도 : {:.2f}%\".format(model2.evaluate(X_test,y_test_encode)[1]*100))\n",
    "# hist = model.fit(train_x,train_y,epochs=300,batch_size=500, validation_data=(test_x, test_y), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 100)               3100      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 80)                8080      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 60)                4860      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 40)                2440      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 20)                820       \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 19,521\n",
      "Trainable params: 19,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer\n",
    "# adam = Adam()\n",
    "# sgd=SGD(lr=0.01,momentum=0.9,decay=0.01)\n",
    "# ad = Adagrad()\n",
    "# rmsprop = RMSprop()\n",
    "#fit a model and plot learning curve\n",
    "def fit_model(X_train,y_train_cata,X_test,y_test_cata,optimizer):\n",
    "    es = EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=10)\n",
    "    mc = ModelCheckpoint('best_model.h5',monitor='val_acc',mode='max',verbose=1,save_best_only=True)\n",
    "    #define model\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_words,64))\n",
    "    model.add(LSTM(128,activation='tanh'))\n",
    "    model.add(Dense(50, input_dim=2,activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    #compile model\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    #fit model\n",
    "    history = model.fit(X_train, y_train_cata, epochs=20, batch_size=10, callbacks=[es,mc],validation_split=0.1,verbose=0.1)\n",
    "    #print 테스트 정확도\n",
    "    print(\"\\n 테스트 정확도 : {:.2f}%\".format(model.evaluate(X_test,y_test_cata)[1]*100))\n",
    "    #plot learning curves\n",
    "    pyplot.plot(history.history['accuracy'],label='train')\n",
    "    pyplot.plot(history.history['val_accuracy'],label='test')\n",
    "    pyplot.title('opt='+optimizer,pad=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:749 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:149 __call__\n        losses = ag_call(y_true, y_pred)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:253 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1535 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4687 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (10, 2) and (10, 3) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-3d2758b96b4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# adam = Adam()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train_encode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test_encode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-98-1c4b75e34f2b>\u001b[0m in \u001b[0;36mfit_model\u001b[1;34m(X_train, y_train_cata, X_test, y_test_cata, optimizer)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m#fit model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_cata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;31m#print 테스트 정확도\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n 테스트 정확도 : {:.2f}%\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test_cata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    821\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 697\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2854\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2855\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2856\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3075\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:749 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:149 __call__\n        losses = ag_call(y_true, y_pred)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:253 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1535 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4687 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (10, 2) and (10, 3) are incompatible\n"
     ]
    }
   ],
   "source": [
    "# adam = Adam()\n",
    "fit_model(X_train,y_train_encode,X_test,y_test_encode,'adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 베이지안 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bayesian-optimization\n",
      "  Downloading bayesian-optimization-1.2.0.tar.gz (14 kB)\n",
      "Requirement already satisfied: numpy>=1.9.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from bayesian-optimization) (1.18.1)\n",
      "Requirement already satisfied: scipy>=0.14.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from bayesian-optimization) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn>=0.18.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from bayesian-optimization) (0.23.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (0.14.1)\n",
      "Building wheels for collected packages: bayesian-optimization\n",
      "  Building wheel for bayesian-optimization (setup.py): started\n",
      "  Building wheel for bayesian-optimization (setup.py): finished with status 'done'\n",
      "  Created wheel for bayesian-optimization: filename=bayesian_optimization-1.2.0-py3-none-any.whl size=11689 sha256=984db3c61c973454b5b37d87832caaa5959ad9dc65c1f371823f920efec4bd7b\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\fd\\9b\\71\\f127d694e02eb40bcf18c7ae9613b88a6be4470f57a8528c5b\n",
      "Successfully built bayesian-optimization\n",
      "Installing collected packages: bayesian-optimization\n",
      "Successfully installed bayesian-optimization-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install bayesian-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-7b327ceb6879>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-7-7b327ceb6879>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    BO_lgb = BayesianOptimization(성능 평가를 수행할 함수, 테스트 수행을 위한 하이퍼 파라미터 Dic,random_state=0)\u001b[0m\n\u001b[1;37m                                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#BaysianOptimization 객체생성\n",
    "BO_lgb = BayesianOptimization(성능 평가를 수행할 함수, 테스트 수행을 위한 하이퍼 파라미터 Dic,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#하이퍼 파라미터 dictionary\n",
    "params={\n",
    "    \n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
