{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기\n",
    "\n",
    "- Human Labeling된 데이터인 SKT , 현대백화점, 현대모비스 데이터 셋을 이용하여 각 정확도를 올린다.\n",
    "\n",
    "- 순서\n",
    "    1. 데이터 불러오기\n",
    "    2. 데이터 분리\n",
    "    3. Title 의 토큰화 및 불용어 제거\n",
    "    4. Label 의 원핫인코딩\n",
    "    5. 길이가 다른 title의 정형화\n",
    "    6. LSTM을 통한 딥러닝\n",
    "    7. 정확도 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_skt = pd.read_csv('../감정분석_V.혜지/title_for_sentiment/total_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mobis = pd.read_csv('./현대모비스_trainset.csv', encoding = 'ANSI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>靑 오찬도 없이 간담회 진행…재계 \"외교로 풀 문제를…\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>김정훈 \"공정위 소비자중심경영 인증기업 24%는 행정조치 처분기업\"</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>산업부 \"코리아 세일 페스타, 상생의 장터 연다\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>박원순, 선거 마지막 날까지 정순균 강남구청장 후보 지원</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>장영철 강남구청장 후보, 선거운동 마지막 주말 총력유세</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>216</td>\n",
       "      <td>입소문 노리려 인플루언서와 공간 나누는 유통업계(종합)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>217</td>\n",
       "      <td>\"인플루언서 모셔라\"…'안방' 내주는 유통업계</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>218</td>\n",
       "      <td>현대百, 고메 아이리시 위크…50여개 아일랜드 식품 브랜드 한자리에</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>219</td>\n",
       "      <td>풍성하고 즐거운 소비 '경험'…진열방식 바꾸는 패션가(종합)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>220</td>\n",
       "      <td>원피스 옆에 샌들·토트백…소비자 취향 DP 고민하는 패션가</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                  Title  label\n",
       "0      0        靑 오찬도 없이 간담회 진행…재계 \"외교로 풀 문제를…\"      0\n",
       "1      1  김정훈 \"공정위 소비자중심경영 인증기업 24%는 행정조치 처분기업\"     -1\n",
       "2      2            산업부 \"코리아 세일 페스타, 상생의 장터 연다\"      1\n",
       "3      3        박원순, 선거 마지막 날까지 정순균 강남구청장 후보 지원      0\n",
       "4      4         장영철 강남구청장 후보, 선거운동 마지막 주말 총력유세      0\n",
       "..   ...                                    ...    ...\n",
       "216  216         입소문 노리려 인플루언서와 공간 나누는 유통업계(종합)      1\n",
       "217  217              \"인플루언서 모셔라\"…'안방' 내주는 유통업계      1\n",
       "218  218  현대百, 고메 아이리시 위크…50여개 아일랜드 식품 브랜드 한자리에      1\n",
       "219  219      풍성하고 즐거운 소비 '경험'…진열방식 바꾸는 패션가(종합)      1\n",
       "220  220       원피스 옆에 샌들·토트백…소비자 취향 DP 고민하는 패션가      0\n",
       "\n",
       "[221 rows x 3 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hb = pd.read_csv('./현대백화점_trainset.csv')\n",
    "df_hb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_skt, df_mobis, df_hb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Title</th>\n",
       "      <th>label</th>\n",
       "      <th>Column1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>국민안전로봇 2021년까지 개발…'로봇물고기' 전철 피할까?</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>'국정원 해킹 의혹' 상임위 앞두고 與野 전초전</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>인터넷티비(TV)결합상품 인터넷가입 비교사이트 통해 통신사별 장단점 비교해야 유리</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>SKT LG KT 인터넷가입 비교사이트 ‘펭귄통신’ 설치 당일 현금지원 이벤트</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>설 연휴 고향 가는 길 언제 출발해야 덜 막힐까</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>216.0</td>\n",
       "      <td>입소문 노리려 인플루언서와 공간 나누는 유통업계(종합)</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>217.0</td>\n",
       "      <td>\"인플루언서 모셔라\"…'안방' 내주는 유통업계</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>218.0</td>\n",
       "      <td>현대百, 고메 아이리시 위크…50여개 아일랜드 식품 브랜드 한자리에</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>219.0</td>\n",
       "      <td>풍성하고 즐거운 소비 '경험'…진열방식 바꾸는 패션가(종합)</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>220.0</td>\n",
       "      <td>원피스 옆에 샌들·토트백…소비자 취향 DP 고민하는 패션가</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>903 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                          Title  label  Column1\n",
       "0      0.0              국민안전로봇 2021년까지 개발…'로봇물고기' 전철 피할까?      0      NaN\n",
       "1      1.0                     '국정원 해킹 의혹' 상임위 앞두고 與野 전초전      0      NaN\n",
       "2      2.0  인터넷티비(TV)결합상품 인터넷가입 비교사이트 통해 통신사별 장단점 비교해야 유리      0      NaN\n",
       "3      3.0    SKT LG KT 인터넷가입 비교사이트 ‘펭귄통신’ 설치 당일 현금지원 이벤트      0      NaN\n",
       "4      4.0                     설 연휴 고향 가는 길 언제 출발해야 덜 막힐까      0      NaN\n",
       "..     ...                                            ...    ...      ...\n",
       "216  216.0                 입소문 노리려 인플루언서와 공간 나누는 유통업계(종합)      1      NaN\n",
       "217  217.0                      \"인플루언서 모셔라\"…'안방' 내주는 유통업계      1      NaN\n",
       "218  218.0          현대百, 고메 아이리시 위크…50여개 아일랜드 식품 브랜드 한자리에      1      NaN\n",
       "219  219.0              풍성하고 즐거운 소비 '경험'…진열방식 바꾸는 패션가(종합)      1      NaN\n",
       "220  220.0               원피스 옆에 샌들·토트백…소비자 취향 DP 고민하는 패션가      0      NaN\n",
       "\n",
       "[903 rows x 4 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train 데이터와 Test 데이터 분리\n",
    "X = df['Title']\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장을 나누기 위한 Stopwords 선정\n",
    "stopwords = ['의', '가', '이', '은', '들', '는', '좀', '잘', '걍', '과', '도', '를', '으로', '자', '에', '와', '한', '하다']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence Tokenizing\n",
    "\n",
    "import konlpy\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()\n",
    "X_train_token = []\n",
    "for sentence in X_train:\n",
    "    temp_X = [] \n",
    "    temp_X = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "    X_train_token.append(temp_X)\n",
    "\n",
    "X_test_token = []\n",
    "for sentence in X_test:\n",
    "    temp_X = []\n",
    "    temp_X = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "    X_test_token.append(temp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Dense, LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "max_words = 35000 \n",
    "tokenizer = Tokenizer(num_words = max_words)\n",
    "tokenizer.fit_on_texts(X_train_token) \n",
    "X_train_token = tokenizer.texts_to_sequences(X_train_token) \n",
    "X_test_token = tokenizer.texts_to_sequences(X_test_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot encoding 2가지 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. \n",
    "import numpy as np\n",
    "y_train_encode = []\n",
    "y_test_encode = []\n",
    "for i in range(len(y_train)):\n",
    "    if y_train.iloc[i] == 1:\n",
    "        y_train_encode.append([0, 0, 1]) \n",
    "    elif y_train.iloc[i] == 0:\n",
    "        y_train_encode.append([0, 1, 0]) \n",
    "    elif y_train.iloc[i] == -1:\n",
    "        y_train_encode.append([1, 0, 0]) \n",
    "        \n",
    "for i in range(len(y_test)):\n",
    "    if y_test.iloc[i] == 1:\n",
    "        y_test_encode.append([0, 0, 1]) \n",
    "    elif y_test.iloc[i] == 0:\n",
    "        y_test_encode.append([0, 1, 0])\n",
    "    elif y_test.iloc[i] == -1:\n",
    "        y_test_encode.append([1, 0, 0]) \n",
    "        \n",
    "y_train_encode=np.array(y_train_encode)\n",
    "y_test_encode=np.array(y_test_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. \n",
    "# to_categorical 방법은 0 1 -1 순서로 인코딩된다!\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train_cata = to_categorical(y_train, num_classes = 3)\n",
    "y_test_cata = to_categorical(y_test, num_classes = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 20 # pad_sequesces이용, 전체 데이터의 길이를 20로 맞춘다\n",
    "X_train = pad_sequences(X_train_token, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test_token, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 [==============================] - 5s 73ms/step - loss: 1.0326 - accuracy: 0.4638 - val_loss: 0.9712 - val_accuracy: 0.4932\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 0.8211 - accuracy: 0.6287 - val_loss: 0.8393 - val_accuracy: 0.6164\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 0.5232 - accuracy: 0.8028 - val_loss: 1.4024 - val_accuracy: 0.6027\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 0.3281 - accuracy: 0.9045 - val_loss: 0.8300 - val_accuracy: 0.6575\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 0.1869 - accuracy: 0.9322 - val_loss: 1.0284 - val_accuracy: 0.6575\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 0.1314 - accuracy: 0.9630 - val_loss: 0.9582 - val_accuracy: 0.6027\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 0.0801 - accuracy: 0.9738 - val_loss: 1.0998 - val_accuracy: 0.6438\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 0.0678 - accuracy: 0.9831 - val_loss: 1.0721 - val_accuracy: 0.6438\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - 3s 43ms/step - loss: 0.0357 - accuracy: 0.9908 - val_loss: 2.1561 - val_accuracy: 0.5068\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - 3s 44ms/step - loss: 0.0369 - accuracy: 0.9861 - val_loss: 1.1324 - val_accuracy: 0.6438\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 100))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "history = model.fit(X_train, y_train_encode, epochs=10, batch_size=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 10ms/step - loss: 1.5661 - accuracy: 0.5691\n",
      "\n",
      " 테스트 정확도 : 56.91%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n 테스트 정확도 : {:.2f}%\".format(model.evaluate(X_test,y_test_encode)[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 현대백화점, SKT, 현대모비스를 합한 데이터를 통해 20%의 비율로 Train과 Test를 나누고 감정 라벨링 결과 57%의 정확도를 보인다. \n",
    "\n",
    "- parameter를 바꿔서 실행해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65/65 [==============================] - 5s 76ms/step - loss: 1.0286 - accuracy: 0.4607 - val_loss: 0.9940 - val_accuracy: 0.5068\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - 4s 55ms/step - loss: 0.7768 - accuracy: 0.6672 - val_loss: 0.7989 - val_accuracy: 0.6712\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - 4s 58ms/step - loss: 0.3056 - accuracy: 0.9106 - val_loss: 0.9088 - val_accuracy: 0.6575\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - 4s 58ms/step - loss: 0.0835 - accuracy: 0.9676 - val_loss: 1.2671 - val_accuracy: 0.6164\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - 4s 58ms/step - loss: 0.0656 - accuracy: 0.9861 - val_loss: 0.9491 - val_accuracy: 0.6301\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - 4s 58ms/step - loss: 0.0944 - accuracy: 0.9738 - val_loss: 0.9956 - val_accuracy: 0.5616\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - 4s 57ms/step - loss: 0.0590 - accuracy: 0.9846 - val_loss: 0.8810 - val_accuracy: 0.5890\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - 4s 58ms/step - loss: 0.0232 - accuracy: 0.9938 - val_loss: 1.0619 - val_accuracy: 0.6301\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - 4s 58ms/step - loss: 0.0139 - accuracy: 0.9969 - val_loss: 1.1865 - val_accuracy: 0.6438\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - 4s 58ms/step - loss: 0.0146 - accuracy: 0.9954 - val_loss: 1.1178 - val_accuracy: 0.6164\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Embedding(max_words, 100))\n",
    "model2.add(LSTM(128))\n",
    "model2.add(Dense(3, activation='softmax'))\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "history = model2.fit(X_train, y_train_encode, epochs=10, batch_size=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 9ms/step - loss: 1.3903 - accuracy: 0.6077\n",
      "\n",
      " 테스트 정확도 : 60.77%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n 테스트 정확도 : {:.2f}%\".format(model2.evaluate(X_test,y_test_encode)[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 약  61% !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "65/65 [==============================] - 5s 82ms/step - loss: 1.0292 - accuracy: 0.4422 - val_loss: 0.9746 - val_accuracy: 0.6301\n",
      "Epoch 2/15\n",
      "65/65 [==============================] - 4s 55ms/step - loss: 0.7420 - accuracy: 0.6949 - val_loss: 0.7983 - val_accuracy: 0.6027\n",
      "Epoch 3/15\n",
      "65/65 [==============================] - 4s 58ms/step - loss: 0.2887 - accuracy: 0.9106 - val_loss: 0.8095 - val_accuracy: 0.6438\n",
      "Epoch 4/15\n",
      "65/65 [==============================] - 4s 65ms/step - loss: 0.0845 - accuracy: 0.9753 - val_loss: 0.9432 - val_accuracy: 0.6164\n",
      "Epoch 5/15\n",
      "65/65 [==============================] - 4s 57ms/step - loss: 0.0470 - accuracy: 0.9846 - val_loss: 0.8571 - val_accuracy: 0.6575\n",
      "Epoch 6/15\n",
      "65/65 [==============================] - 4s 57ms/step - loss: 0.0400 - accuracy: 0.9938 - val_loss: 0.9695 - val_accuracy: 0.5890\n",
      "Epoch 7/15\n",
      "65/65 [==============================] - 4s 57ms/step - loss: 0.0180 - accuracy: 0.9938 - val_loss: 1.1330 - val_accuracy: 0.6575\n",
      "Epoch 8/15\n",
      "65/65 [==============================] - 4s 57ms/step - loss: 0.0148 - accuracy: 0.9969 - val_loss: 0.9403 - val_accuracy: 0.6164\n",
      "Epoch 9/15\n",
      "65/65 [==============================] - 4s 58ms/step - loss: 0.0132 - accuracy: 0.9954 - val_loss: 1.2279 - val_accuracy: 0.6575\n",
      "Epoch 10/15\n",
      "65/65 [==============================] - 4s 57ms/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 1.0700 - val_accuracy: 0.6575\n",
      "Epoch 11/15\n",
      "65/65 [==============================] - 4s 56ms/step - loss: 0.0093 - accuracy: 0.9954 - val_loss: 1.2694 - val_accuracy: 0.6575\n",
      "Epoch 12/15\n",
      "65/65 [==============================] - 4s 57ms/step - loss: 0.0077 - accuracy: 0.9969 - val_loss: 1.1679 - val_accuracy: 0.6712\n",
      "Epoch 13/15\n",
      "65/65 [==============================] - 4s 57ms/step - loss: 0.0064 - accuracy: 0.9954 - val_loss: 1.3393 - val_accuracy: 0.6301\n",
      "Epoch 14/15\n",
      "65/65 [==============================] - 4s 58ms/step - loss: 0.0119 - accuracy: 0.9938 - val_loss: 1.2007 - val_accuracy: 0.6301\n",
      "Epoch 15/15\n",
      "65/65 [==============================] - 4s 57ms/step - loss: 0.0079 - accuracy: 0.9938 - val_loss: 1.2008 - val_accuracy: 0.6438\n"
     ]
    }
   ],
   "source": [
    "# adam 모델 epoch 15로 실행\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(max_words, 100))\n",
    "model2.add(LSTM(128))\n",
    "model2.add(Dense(3, activation='softmax'))\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "history = model2.fit(X_train, y_train_encode, epochs=15, batch_size=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 8ms/step - loss: 1.6380 - accuracy: 0.6188\n",
      "\n",
      " 테스트 정확도 : 61.88%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n 테스트 정확도 : {:.2f}%\".format(model2.evaluate(X_test,y_test_encode)[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skt ,현대모비스, 현백 데이터를 합쳐서 현대백화점 종목을 추론하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "hb_test = pd.read_csv('./현대백화점_testset.csv', encoding = 'ANSI')\n",
    "# df = 현백 ,현모, SKT 데이터를 합친것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df['Title']\n",
    "X_test = hb_test['Title']\n",
    "\n",
    "y_train = df['label']\n",
    "y_test = hb_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장을 나누기 위한 Stopwords 선정\n",
    "stopwords = ['의', '가', '이', '은', '들', '는', '좀', '잘', '걍', '과', '도', '를', '으로', '자', '에', '와', '한', '하다']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# Sentence Tokenizing\n",
    "import konlpy\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()\n",
    "X_train_token = []\n",
    "for sentence in X_train:\n",
    "    temp_X = [] \n",
    "    temp_X = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "    X_train_token.append(temp_X)\n",
    "\n",
    "X_test_token = []\n",
    "for sentence in X_test:\n",
    "    temp_X = []\n",
    "    temp_X = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "    X_test_token.append(temp_X)\n",
    "from keras.layers import Embedding, Dense, LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "max_words = 35000 \n",
    "tokenizer = Tokenizer(num_words = max_words)\n",
    "tokenizer.fit_on_texts(X_train_token) \n",
    "X_train_token = tokenizer.texts_to_sequences(X_train_token) \n",
    "X_test_token = tokenizer.texts_to_sequences(X_test_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_train_encode = []\n",
    "y_test_encode = []\n",
    "for i in range(len(y_train)):\n",
    "    if y_train.iloc[i] == 1:\n",
    "        y_train_encode.append([0, 0, 1]) \n",
    "    elif y_train.iloc[i] == 0:\n",
    "        y_train_encode.append([0, 1, 0]) \n",
    "    elif y_train.iloc[i] == -1:\n",
    "        y_train_encode.append([1, 0, 0]) \n",
    "        \n",
    "for i in range(len(y_test)):\n",
    "    if y_test.iloc[i] == 1:\n",
    "        y_test_encode.append([0, 0, 1]) \n",
    "    elif y_test.iloc[i] == 0:\n",
    "        y_test_encode.append([0, 1, 0])\n",
    "    elif y_test.iloc[i] == -1:\n",
    "        y_test_encode.append([1, 0, 0]) \n",
    "        \n",
    "y_train_encode=np.array(y_train_encode)\n",
    "y_test_encode=np.array(y_test_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 20 # pad_sequesces이용, 전체 데이터의 길이를 20로 맞춘다\n",
    "X_train = pad_sequences(X_train_token, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test_token, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "82/82 [==============================] - 2s 30ms/step - loss: 1.0177 - accuracy: 0.4852 - val_loss: 1.0752 - val_accuracy: 0.2308\n",
      "Epoch 2/10\n",
      "82/82 [==============================] - 2s 22ms/step - loss: 0.8050 - accuracy: 0.6650 - val_loss: 0.6776 - val_accuracy: 0.7253\n",
      "Epoch 3/10\n",
      "82/82 [==============================] - 2s 22ms/step - loss: 0.5233 - accuracy: 0.8067 - val_loss: 1.1093 - val_accuracy: 0.4945\n",
      "Epoch 4/10\n",
      "82/82 [==============================] - 2s 23ms/step - loss: 0.3335 - accuracy: 0.8904 - val_loss: 0.6651 - val_accuracy: 0.7363\n",
      "Epoch 5/10\n",
      "82/82 [==============================] - 2s 24ms/step - loss: 0.1922 - accuracy: 0.9384 - val_loss: 0.9113 - val_accuracy: 0.6374\n",
      "Epoch 6/10\n",
      "82/82 [==============================] - 2s 22ms/step - loss: 0.1265 - accuracy: 0.9594 - val_loss: 1.0822 - val_accuracy: 0.5714\n",
      "Epoch 7/10\n",
      "82/82 [==============================] - 2s 21ms/step - loss: 0.0820 - accuracy: 0.9741 - val_loss: 0.8833 - val_accuracy: 0.6593\n",
      "Epoch 8/10\n",
      "82/82 [==============================] - 2s 22ms/step - loss: 0.0560 - accuracy: 0.9803 - val_loss: 1.3723 - val_accuracy: 0.5604\n",
      "Epoch 9/10\n",
      "82/82 [==============================] - 2s 22ms/step - loss: 0.0377 - accuracy: 0.9877 - val_loss: 1.3322 - val_accuracy: 0.6154\n",
      "Epoch 10/10\n",
      "82/82 [==============================] - 2s 22ms/step - loss: 0.0223 - accuracy: 0.9926 - val_loss: 1.2148 - val_accuracy: 0.6813\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 100))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "history = model.fit(X_train, y_train_encode, epochs=10, batch_size=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 3.3818 - accuracy: 0.5000\n",
      "\n",
      " 테스트 정확도 : 50.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n 테스트 정확도 : {:.2f}%\".format(model.evaluate(X_test,y_test_encode)[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "82/82 [==============================] - 4s 53ms/step - loss: 1.0280 - accuracy: 0.4643 - val_loss: 0.7238 - val_accuracy: 0.8681\n",
      "Epoch 2/10\n",
      "82/82 [==============================] - 3s 42ms/step - loss: 0.7153 - accuracy: 0.6933 - val_loss: 0.6411 - val_accuracy: 0.7363\n",
      "Epoch 3/10\n",
      "82/82 [==============================] - 4s 45ms/step - loss: 0.2450 - accuracy: 0.9187 - val_loss: 0.6358 - val_accuracy: 0.7473\n",
      "Epoch 4/10\n",
      "82/82 [==============================] - 3s 41ms/step - loss: 0.0684 - accuracy: 0.9815 - val_loss: 0.9539 - val_accuracy: 0.6484\n",
      "Epoch 5/10\n",
      "82/82 [==============================] - 3s 41ms/step - loss: 0.0452 - accuracy: 0.9889 - val_loss: 0.8049 - val_accuracy: 0.6923\n",
      "Epoch 6/10\n",
      "82/82 [==============================] - 3s 42ms/step - loss: 0.0214 - accuracy: 0.9963 - val_loss: 0.8072 - val_accuracy: 0.7143\n",
      "Epoch 7/10\n",
      "82/82 [==============================] - 3s 41ms/step - loss: 0.0230 - accuracy: 0.9914 - val_loss: 0.8869 - val_accuracy: 0.7143\n",
      "Epoch 8/10\n",
      "82/82 [==============================] - 3s 42ms/step - loss: 0.0353 - accuracy: 0.9914 - val_loss: 0.7961 - val_accuracy: 0.6813\n",
      "Epoch 9/10\n",
      "82/82 [==============================] - 3s 41ms/step - loss: 0.0150 - accuracy: 0.9988 - val_loss: 0.8828 - val_accuracy: 0.7692\n",
      "Epoch 10/10\n",
      "82/82 [==============================] - 3s 42ms/step - loss: 0.0078 - accuracy: 0.9988 - val_loss: 2.1973 - val_accuracy: 0.4945\n"
     ]
    }
   ],
   "source": [
    "# adam 모델 epoch 15로 실행\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(max_words, 100))\n",
    "model2.add(LSTM(128))\n",
    "model2.add(Dense(3, activation='softmax'))\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) \n",
    "history = model2.fit(X_train, y_train_encode, epochs=15, batch_size=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 3.1094 - accuracy: 0.5476\n",
      "\n",
      " 테스트 정확도 : 54.76%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n 테스트 정확도 : {:.2f}%\".format(model2.evaluate(X_test,y_test_encode)[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "163/163 [==============================] - 7s 40ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.9033 - val_accuracy: 0.7802\n",
      "Epoch 2/5\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.8677 - val_accuracy: 0.7912\n",
      "Epoch 3/5\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 0.0063 - accuracy: 0.9975 - val_loss: 0.8976 - val_accuracy: 0.7473\n",
      "Epoch 4/5\n",
      "163/163 [==============================] - 7s 40ms/step - loss: 0.0031 - accuracy: 0.9975 - val_loss: 0.9184 - val_accuracy: 0.7912\n",
      "Epoch 5/5\n",
      "163/163 [==============================] - 7s 41ms/step - loss: 0.0022 - accuracy: 0.9988 - val_loss: 0.9936 - val_accuracy: 0.7802\n"
     ]
    }
   ],
   "source": [
    "history = model2.fit(X_train, y_train_encode, epochs=5, batch_size=5, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 3.1405 - accuracy: 0.5476\n",
      "\n",
      " 테스트 정확도 : 54.76%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n 테스트 정확도 : {:.2f}%\".format(model2.evaluate(X_test,y_test_encode)[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
