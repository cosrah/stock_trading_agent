{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mxnet-cu101\n",
      "  Using cached mxnet_cu101-1.5.0-py2.py3-none-win_amd64.whl (385.0 MB)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from mxnet-cu101) (0.8.4)\n",
      "Collecting requests<2.19.0,>=2.18.4\n",
      "  Using cached requests-2.18.4-py2.py3-none-any.whl (88 kB)\n",
      "Collecting numpy<1.17.0,>=1.8.2\n",
      "  Using cached numpy-1.16.6.zip (5.1 MB)\n",
      "Collecting idna<2.7,>=2.5\n",
      "  Using cached idna-2.6-py2.py3-none-any.whl (56 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<2.19.0,>=2.18.4->mxnet-cu101) (2020.6.20)\n",
      "Collecting urllib3<1.23,>=1.21.1\n",
      "  Using cached urllib3-1.22-py2.py3-none-any.whl (132 kB)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<2.19.0,>=2.18.4->mxnet-cu101) (3.0.4)\n",
      "Building wheels for collected packages: numpy\n",
      "  Building wheel for numpy (setup.py): started\n",
      "  Building wheel for numpy (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for numpy\n",
      "Failed to build numpy\n",
      "Installing collected packages: idna, urllib3, requests, numpy, mxnet-cu101\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 2.10\n",
      "    Uninstalling idna-2.10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\ProgramData\\Anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\강의장\\\\AppData\\\\Local\\\\Temp\\\\pip-install-j_rcgb1d\\\\numpy\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\강의장\\\\AppData\\\\Local\\\\Temp\\\\pip-install-j_rcgb1d\\\\numpy\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\강의장\\AppData\\Local\\Temp\\pip-wheel-0obkqhwp'\n",
      "       cwd: C:\\Users\\강의장\\AppData\\Local\\Temp\\pip-install-j_rcgb1d\\numpy\\\n",
      "  Complete output (264 lines):\n",
      "  Running from numpy source directory.\n",
      "  C:\\Users\\강의장\\AppData\\Local\\Temp\\pip-install-j_rcgb1d\\numpy\\numpy\\distutils\\misc_util.py:476: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "    return is_string(s) and ('*' in s or '?' is s)\n",
      "  blas_opt_info:\n",
      "  blas_mkl_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries mkl_rt not found in ['C:\\\\ProgramData\\\\Anaconda3\\\\lib', 'C:\\\\', 'C:\\\\ProgramData\\\\Anaconda3\\\\libs']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  blis_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries blis not found in ['C:\\\\ProgramData\\\\Anaconda3\\\\lib', 'C:\\\\', 'C:\\\\ProgramData\\\\Anaconda3\\\\libs']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  openblas_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries openblas not found in ['C:\\\\ProgramData\\\\Anaconda3\\\\lib', 'C:\\\\', 'C:\\\\ProgramData\\\\Anaconda3\\\\libs']\n",
      "  get_default_fcompiler: matching types: '['gnu', 'intelv', 'absoft', 'compaqv', 'intelev', 'gnu95', 'g95', 'intelvem', 'intelem', 'flang']'\n",
      "  customize GnuFCompiler\n",
      "  Could not locate executable g77\n",
      "  Could not locate executable f77\n",
      "  customize IntelVisualFCompiler\n",
      "  Could not locate executable ifort\n",
      "  Could not locate executable ifl\n",
      "  customize AbsoftFCompiler\n",
      "  Could not locate executable f90\n",
      "  customize CompaqVisualFCompiler\n",
      "  Could not locate executable DF\n",
      "  customize IntelItaniumVisualFCompiler\n",
      "  Could not locate executable efl\n",
      "  customize Gnu95FCompiler\n",
      "  Could not locate executable gfortran\n",
      "  Could not locate executable f95\n",
      "  customize G95FCompiler\n",
      "  Could not locate executable g95\n",
      "  customize IntelEM64VisualFCompiler\n",
      "  customize IntelEM64TFCompiler\n",
      "  Could not locate executable efort\n",
      "  Could not locate executable efc\n",
      "  customize PGroupFlangCompiler\n",
      "  Could not locate executable flang\n",
      "  don't know how to compile Fortran code on platform 'nt'\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_3_10_blas_threads_info:\n",
      "  Setting PTATLAS=ATLAS\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries tatlas not found in ['C:\\\\ProgramData\\\\Anaconda3\\\\lib', 'C:\\\\', 'C:\\\\ProgramData\\\\Anaconda3\\\\libs']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_3_10_blas_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries satlas not found in ['C:\\\\ProgramData\\\\Anaconda3\\\\lib', 'C:\\\\', 'C:\\\\ProgramData\\\\Anaconda3\\\\libs']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_blas_threads_info:\n",
      "  Setting PTATLAS=ATLAS\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries ptf77blas,ptcblas,atlas not found in ['C:\\\\ProgramData\\\\Anaconda3\\\\lib', 'C:\\\\', 'C:\\\\ProgramData\\\\Anaconda3\\\\libs']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_blas_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries f77blas,cblas,atlas not found in ['C:\\\\ProgramData\\\\Anaconda3\\\\lib', 'C:\\\\', 'C:\\\\ProgramData\\\\Anaconda3\\\\libs']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  accelerate_info:\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  C:\\Users\\강의장\\AppData\\Local\\Temp\\pip-install-j_rcgb1d\\numpy\\numpy\\distutils\\system_info.py:639: UserWarning:\n",
      "      Atlas (http://math-atlas.sourceforge.net/) libraries not found.\n",
      "      Directories to search for the libraries can be specified in the\n",
      "      numpy/distutils/site.cfg file (section [atlas]) or by setting\n",
      "      the ATLAS environment variable.\n",
      "    self.calc_info()\n",
      "  blas_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries blas not found in ['C:\\\\ProgramData\\\\Anaconda3\\\\lib', 'C:\\\\', 'C:\\\\ProgramData\\\\Anaconda3\\\\libs']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  C:\\Users\\강의장\\AppData\\Local\\Temp\\pip-install-j_rcgb1d\\numpy\\numpy\\distutils\\system_info.py:639: UserWarning:\n",
      "      Blas (http://www.netlib.org/blas/) libraries not found.\n",
      "      Directories to search for the libraries can be specified in the\n",
      "      numpy/distutils/site.cfg file (section [blas]) or by setting\n",
      "      the BLAS environment variable.\n",
      "    self.calc_info()\n",
      "  blas_src_info:\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  C:\\Users\\강의장\\AppData\\Local\\Temp\\pip-install-j_rcgb1d\\numpy\\numpy\\distutils\\system_info.py:639: UserWarning:\n",
      "      Blas (http://www.netlib.org/blas/) sources not found.\n",
      "      Directories to search for the sources can be specified in the\n",
      "      numpy/distutils/site.cfg file (section [blas_src]) or by setting\n",
      "      the BLAS_SRC environment variable.\n",
      "    self.calc_info()\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  'svnversion'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "  배치 파일이 아닙니다.\n",
      "  non-existing path in 'numpy\\\\distutils': 'site.cfg'\n",
      "  lapack_opt_info:\n",
      "  lapack_mkl_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries mkl_rt not found in ['C:\\\\ProgramData\\\\Anaconda3\\\\lib', 'C:\\\\', 'C:\\\\ProgramData\\\\Anaconda3\\\\libs']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  openblas_lapack_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries openblas not found in ['C:\\\\ProgramData\\\\Anaconda3\\\\lib', 'C:\\\\', 'C:\\\\ProgramData\\\\Anaconda3\\\\libs']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  openblas_clapack_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries openblas,lapack not found in ['C:\\\\ProgramData\\\\Anaconda3\\\\lib', 'C:\\\\', 'C:\\\\ProgramData\\\\Anaconda3\\\\libs']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_3_10_threads_info:\n",
      "  Setting PTATLAS=ATLAS\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\ProgramData\\Anaconda3\\lib\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries tatlas,tatlas not found in C:\\ProgramData\\Anaconda3\\lib\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries tatlas,tatlas not found in C:\\\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\ProgramData\\Anaconda3\\libs\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries tatlas,tatlas not found in C:\\ProgramData\\Anaconda3\\libs\n",
      "  <class 'numpy.distutils.system_info.atlas_3_10_threads_info'>\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_3_10_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\ProgramData\\Anaconda3\\lib\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries satlas,satlas not found in C:\\ProgramData\\Anaconda3\\lib\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries satlas,satlas not found in C:\\\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\ProgramData\\Anaconda3\\libs\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries satlas,satlas not found in C:\\ProgramData\\Anaconda3\\libs\n",
      "  <class 'numpy.distutils.system_info.atlas_3_10_info'>\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_threads_info:\n",
      "  Setting PTATLAS=ATLAS\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\ProgramData\\Anaconda3\\lib\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries ptf77blas,ptcblas,atlas not found in C:\\ProgramData\\Anaconda3\\lib\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries ptf77blas,ptcblas,atlas not found in C:\\\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\ProgramData\\Anaconda3\\libs\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries ptf77blas,ptcblas,atlas not found in C:\\ProgramData\\Anaconda3\\libs\n",
      "  <class 'numpy.distutils.system_info.atlas_threads_info'>\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\ProgramData\\Anaconda3\\lib\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries f77blas,cblas,atlas not found in C:\\ProgramData\\Anaconda3\\lib\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries f77blas,cblas,atlas not found in C:\\\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack_atlas not found in C:\\ProgramData\\Anaconda3\\libs\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries f77blas,cblas,atlas not found in C:\\ProgramData\\Anaconda3\\libs\n",
      "  <class 'numpy.distutils.system_info.atlas_info'>\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  lapack_info:\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  customize MSVCCompiler\n",
      "    libraries lapack not found in ['C:\\\\ProgramData\\\\Anaconda3\\\\lib', 'C:\\\\', 'C:\\\\ProgramData\\\\Anaconda3\\\\libs']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  C:\\Users\\강의장\\AppData\\Local\\Temp\\pip-install-j_rcgb1d\\numpy\\numpy\\distutils\\system_info.py:639: UserWarning:\n",
      "      Lapack (http://www.netlib.org/lapack/) libraries not found.\n",
      "      Directories to search for the libraries can be specified in the\n",
      "      numpy/distutils/site.cfg file (section [lapack]) or by setting\n",
      "      the LAPACK environment variable.\n",
      "    self.calc_info()\n",
      "  lapack_src_info:\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  C:\\Users\\강의장\\AppData\\Local\\Temp\\pip-install-j_rcgb1d\\numpy\\numpy\\distutils\\system_info.py:639: UserWarning:\n",
      "      Lapack (http://www.netlib.org/lapack/) sources not found.\n",
      "      Directories to search for the sources can be specified in the\n",
      "      numpy/distutils/site.cfg file (section [lapack_src]) or by setting\n",
      "      the LAPACK_SRC environment variable.\n",
      "    self.calc_info()\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  C:\\ProgramData\\Anaconda3\\lib\\distutils\\dist.py:274: UserWarning: Unknown distribution option: 'define_macros'\n",
      "    warnings.warn(msg)\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running config_cc\n",
      "  unifing config_cc, config, build_clib, build_ext, build commands --compiler options\n",
      "  running config_fc\n",
      "  unifing config_fc, config, build_clib, build_ext, build commands --fcompiler options\n",
      "  running build_src\n",
      "  build_src\n",
      "  building py_modules sources\n",
      "  creating build\n",
      "  creating build\\src.win-amd64-3.8\n",
      "  creating build\\src.win-amd64-3.8\\numpy\n",
      "  creating build\\src.win-amd64-3.8\\numpy\\distutils\n",
      "  building library \"npymath\" sources\n",
      "  No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "  error: Microsoft Visual C++ 14.0 is required. Get it with \"Build Tools for Visual Studio\": https://visualstudio.microsoft.com/downloads/\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for numpy\n",
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\ProgramData\\Anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\강의장\\\\AppData\\\\Local\\\\Temp\\\\pip-install-j_rcgb1d\\\\numpy\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\강의장\\\\AppData\\\\Local\\\\Temp\\\\pip-install-j_rcgb1d\\\\numpy\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' clean --all\n",
      "       cwd: C:\\Users\\강의장\\AppData\\Local\\Temp\\pip-install-j_rcgb1d\\numpy\n",
      "  Complete output (10 lines):\n",
      "  Running from numpy source directory.\n",
      "  \n",
      "  `setup.py clean` is not supported, use one of the following instead:\n",
      "  \n",
      "    - `git clean -xdf` (cleans all files)\n",
      "    - `git clean -Xdf` (cleans all versioned files, doesn't touch\n",
      "                        files that aren't checked into the git repo)\n",
      "  \n",
      "  Add `--force` to your command to use it anyway if you must (unsupported).\n",
      "  \n",
      "  ----------------------------------------\n",
      "  ERROR: Failed cleaning build dir for numpy\n",
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] 액세스가 거부되었습니다: 'c:\\\\programdata\\\\anaconda3\\\\lib\\\\site-packages\\\\idna-2.10.dist-info\\\\direct_url.json'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gluonnlp"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\ProgramData\\Anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\강의장\\\\AppData\\\\Local\\\\Temp\\\\pip-install-6yaywths\\\\gluonnlp\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\강의장\\\\AppData\\\\Local\\\\Temp\\\\pip-install-6yaywths\\\\gluonnlp\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\강의장\\AppData\\Local\\Temp\\pip-wheel-sscgb9f_'\n",
      "       cwd: C:\\Users\\강의장\\AppData\\Local\\Temp\\pip-install-6yaywths\\gluonnlp\\\n",
      "  Complete output (123 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-3.8\n",
      "  creating build\\lib.win-amd64-3.8\\gluonnlp\n",
      "  copying src\\gluonnlp\\base.py -> build\\lib.win-amd64-3.8\\gluonnlp\n",
      "  copying src\\gluonnlp\\_constants.py -> build\\lib.win-amd64-3.8\\gluonnlp\n",
      "  copying src\\gluonnlp\\__init__.py -> build\\lib.win-amd64-3.8\\gluonnlp\n",
      "  creating build\\lib.win-amd64-3.8\\gluonnlp\\calibration\n",
      "  copying src\\gluonnlp\\calibration\\collector.py -> build\\lib.win-amd64-3.8\\gluonnlp\\calibration\n",
      "  copying src\\gluonnlp\\calibration\\__init__.py -> build\\lib.win-amd64-3.8\\gluonnlp\\calibration\n",
      "  creating build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\baidu_ernie_data.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\candidate_sampler.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\classification.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\conll.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\dataloader.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\dataset.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\datasetloader.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\glue.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\intent_slot.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\question_answering.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\registry.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\sampler.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\sentiment.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\stream.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\super_glue.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\transforms.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\translation.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\utils.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\word_embedding_evaluation.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\__init__.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "  creating build\\lib.win-amd64-3.8\\gluonnlp\\embedding\n",
      "  copying src\\gluonnlp\\embedding\\evaluation.py -> build\\lib.win-amd64-3.8\\gluonnlp\\embedding\n",
      "  copying src\\gluonnlp\\embedding\\token_embedding.py -> build\\lib.win-amd64-3.8\\gluonnlp\\embedding\n",
      "  copying src\\gluonnlp\\embedding\\__init__.py -> build\\lib.win-amd64-3.8\\gluonnlp\\embedding\n",
      "  creating build\\lib.win-amd64-3.8\\gluonnlp\\initializer\n",
      "  copying src\\gluonnlp\\initializer\\initializer.py -> build\\lib.win-amd64-3.8\\gluonnlp\\initializer\n",
      "  copying src\\gluonnlp\\initializer\\__init__.py -> build\\lib.win-amd64-3.8\\gluonnlp\\initializer\n",
      "  creating build\\lib.win-amd64-3.8\\gluonnlp\\loss\n",
      "  copying src\\gluonnlp\\loss\\activation_regularizer.py -> build\\lib.win-amd64-3.8\\gluonnlp\\loss\n",
      "  copying src\\gluonnlp\\loss\\label_smoothing.py -> build\\lib.win-amd64-3.8\\gluonnlp\\loss\n",
      "  copying src\\gluonnlp\\loss\\loss.py -> build\\lib.win-amd64-3.8\\gluonnlp\\loss\n",
      "  copying src\\gluonnlp\\loss\\__init__.py -> build\\lib.win-amd64-3.8\\gluonnlp\\loss\n",
      "  creating build\\lib.win-amd64-3.8\\gluonnlp\\metric\n",
      "  copying src\\gluonnlp\\metric\\length_normalized_loss.py -> build\\lib.win-amd64-3.8\\gluonnlp\\metric\n",
      "  copying src\\gluonnlp\\metric\\masked_accuracy.py -> build\\lib.win-amd64-3.8\\gluonnlp\\metric\n",
      "  copying src\\gluonnlp\\metric\\__init__.py -> build\\lib.win-amd64-3.8\\gluonnlp\\metric\n",
      "  creating build\\lib.win-amd64-3.8\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\attention_cell.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\bert.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\bilm_encoder.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\block.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\convolutional_encoder.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\elmo.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\highway.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\info.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\language_model.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\lstmpcellwithclip.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\parameter.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\sampled_block.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\seq2seq_encoder_decoder.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\sequence_sampler.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\transformer.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\translation.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\utils.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\n",
      "  copying src\\gluonnlp\\model\\__init__.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\n",
      "  creating build\\lib.win-amd64-3.8\\gluonnlp\\optimizer\n",
      "  copying src\\gluonnlp\\optimizer\\bert_adam.py -> build\\lib.win-amd64-3.8\\gluonnlp\\optimizer\n",
      "  copying src\\gluonnlp\\optimizer\\__init__.py -> build\\lib.win-amd64-3.8\\gluonnlp\\optimizer\n",
      "  creating build\\lib.win-amd64-3.8\\gluonnlp\\utils\n",
      "  copying src\\gluonnlp\\utils\\files.py -> build\\lib.win-amd64-3.8\\gluonnlp\\utils\n",
      "  copying src\\gluonnlp\\utils\\parallel.py -> build\\lib.win-amd64-3.8\\gluonnlp\\utils\n",
      "  copying src\\gluonnlp\\utils\\parameter.py -> build\\lib.win-amd64-3.8\\gluonnlp\\utils\n",
      "  copying src\\gluonnlp\\utils\\seed.py -> build\\lib.win-amd64-3.8\\gluonnlp\\utils\n",
      "  copying src\\gluonnlp\\utils\\version.py -> build\\lib.win-amd64-3.8\\gluonnlp\\utils\n",
      "  copying src\\gluonnlp\\utils\\__init__.py -> build\\lib.win-amd64-3.8\\gluonnlp\\utils\n",
      "  creating build\\lib.win-amd64-3.8\\gluonnlp\\vocab"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached gluonnlp-0.10.0.tar.gz (344 kB)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (1.0.5)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (4.47.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gluonnlp) (1.18.5)\n",
      "Requirement already satisfied: cython in c:\\programdata\\anaconda3\\lib\\site-packages (from gluonnlp) (0.29.21)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from gluonnlp) (20.4)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->gluonnlp) (2.4.7)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->gluonnlp) (1.15.0)\n",
      "Building wheels for collected packages: gluonnlp\n",
      "  Building wheel for gluonnlp (setup.py): started\n",
      "  Building wheel for gluonnlp (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for gluonnlp\n",
      "Failed to build gluonnlp\n",
      "Installing collected packages: gluonnlp\n",
      "    Running setup.py install for gluonnlp: started\n",
      "    Running setup.py install for gluonnlp: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  copying src\\gluonnlp\\vocab\\bert.py -> build\\lib.win-amd64-3.8\\gluonnlp\\vocab\n",
      "  copying src\\gluonnlp\\vocab\\elmo.py -> build\\lib.win-amd64-3.8\\gluonnlp\\vocab\n",
      "  copying src\\gluonnlp\\vocab\\subwords.py -> build\\lib.win-amd64-3.8\\gluonnlp\\vocab\n",
      "  copying src\\gluonnlp\\vocab\\vocab.py -> build\\lib.win-amd64-3.8\\gluonnlp\\vocab\n",
      "  copying src\\gluonnlp\\vocab\\__init__.py -> build\\lib.win-amd64-3.8\\gluonnlp\\vocab\n",
      "  creating build\\lib.win-amd64-3.8\\gluonnlp\\data\\batchify\n",
      "  copying src\\gluonnlp\\data\\batchify\\batchify.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\\batchify\n",
      "  copying src\\gluonnlp\\data\\batchify\\embedding.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\\batchify\n",
      "  copying src\\gluonnlp\\data\\batchify\\language_model.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\\batchify\n",
      "  copying src\\gluonnlp\\data\\batchify\\__init__.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\\batchify\n",
      "  creating build\\lib.win-amd64-3.8\\gluonnlp\\data\\bert\n",
      "  copying src\\gluonnlp\\data\\bert\\glue.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\\bert\n",
      "  copying src\\gluonnlp\\data\\bert\\squad.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\\bert\n",
      "  copying src\\gluonnlp\\data\\bert\\__init__.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\\bert\n",
      "  creating build\\lib.win-amd64-3.8\\gluonnlp\\data\\corpora\n",
      "  copying src\\gluonnlp\\data\\corpora\\google_billion_word.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\\corpora\n",
      "  copying src\\gluonnlp\\data\\corpora\\large_text_compression_benchmark.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\\corpora\n",
      "  copying src\\gluonnlp\\data\\corpora\\wikitext.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\\corpora\n",
      "  copying src\\gluonnlp\\data\\corpora\\__init__.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\\corpora\n",
      "  creating build\\lib.win-amd64-3.8\\gluonnlp\\data\\xlnet\n",
      "  copying src\\gluonnlp\\data\\xlnet\\squad.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\\xlnet\n",
      "  copying src\\gluonnlp\\data\\xlnet\\__init__.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\\xlnet\n",
      "  creating build\\lib.win-amd64-3.8\\gluonnlp\\model\\train\n",
      "  copying src\\gluonnlp\\model\\train\\cache.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\\train\n",
      "  copying src\\gluonnlp\\model\\train\\embedding.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\\train\n",
      "  copying src\\gluonnlp\\model\\train\\language_model.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\\train\n",
      "  copying src\\gluonnlp\\model\\train\\__init__.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\\train\n",
      "  running egg_info\n",
      "  writing src\\gluonnlp.egg-info\\PKG-INFO\n",
      "  writing dependency_links to src\\gluonnlp.egg-info\\dependency_links.txt\n",
      "  writing requirements to src\\gluonnlp.egg-info\\requires.txt\n",
      "  writing top-level names to src\\gluonnlp.egg-info\\top_level.txt\n",
      "  reading manifest file 'src\\gluonnlp.egg-info\\SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  warning: no files found matching '*.py' under directory 'gluonnlp'\n",
      "  warning: no previously-included files matching '*' found under directory 'tests'\n",
      "  warning: no previously-included files matching '*' found under directory 'scripts'\n",
      "  writing manifest file 'src\\gluonnlp.egg-info\\SOURCES.txt'\n",
      "  copying src\\gluonnlp\\data\\fast_bert_tokenizer.c -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "  copying src\\gluonnlp\\data\\fast_bert_tokenizer.pyx -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "  running build_ext\n",
      "  skipping 'src/gluonnlp/data\\fast_bert_tokenizer.c' Cython extension (up-to-date)\n",
      "  building 'gluonnlp.data.fast_bert_tokenizer' extension\n",
      "  error: Microsoft Visual C++ 14.0 is required. Get it with \"Build Tools for Visual Studio\": https://visualstudio.microsoft.com/downloads/\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for gluonnlp\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'C:\\ProgramData\\Anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\강의장\\\\AppData\\\\Local\\\\Temp\\\\pip-install-6yaywths\\\\gluonnlp\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\강의장\\\\AppData\\\\Local\\\\Temp\\\\pip-install-6yaywths\\\\gluonnlp\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\강의장\\AppData\\Local\\Temp\\pip-record-7i3o1_ny\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\ProgramData\\Anaconda3\\Include\\gluonnlp'\n",
      "         cwd: C:\\Users\\강의장\\AppData\\Local\\Temp\\pip-install-6yaywths\\gluonnlp\\\n",
      "    Complete output (123 lines):\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build\\lib.win-amd64-3.8\n",
      "    creating build\\lib.win-amd64-3.8\\gluonnlp\n",
      "    copying src\\gluonnlp\\base.py -> build\\lib.win-amd64-3.8\\gluonnlp\n",
      "    copying src\\gluonnlp\\_constants.py -> build\\lib.win-amd64-3.8\\gluonnlp\n",
      "    copying src\\gluonnlp\\__init__.py -> build\\lib.win-amd64-3.8\\gluonnlp\n",
      "    creating build\\lib.win-amd64-3.8\\gluonnlp\\calibration\n",
      "    copying src\\gluonnlp\\calibration\\collector.py -> build\\lib.win-amd64-3.8\\gluonnlp\\calibration\n",
      "    copying src\\gluonnlp\\calibration\\__init__.py -> build\\lib.win-amd64-3.8\\gluonnlp\\calibration\n",
      "    creating build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\baidu_ernie_data.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\candidate_sampler.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\classification.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\conll.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\dataloader.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\dataset.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\datasetloader.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\glue.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\intent_slot.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\question_answering.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\registry.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\sampler.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\sentiment.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\stream.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\super_glue.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\transforms.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\translation.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\utils.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\word_embedding_evaluation.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\__init__.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "    creating build\\lib.win-amd64-3.8\\gluonnlp\\embedding\n",
      "    copying src\\gluonnlp\\embedding\\evaluation.py -> build\\lib.win-amd64-3.8\\gluonnlp\\embedding\n",
      "    copying src\\gluonnlp\\embedding\\token_embedding.py -> build\\lib.win-amd64-3.8\\gluonnlp\\embedding\n",
      "    copying src\\gluonnlp\\embedding\\__init__.py -> build\\lib.win-amd64-3.8\\gluonnlp\\embedding\n",
      "    creating build\\lib.win-amd64-3.8\\gluonnlp\\initializer\n",
      "    copying src\\gluonnlp\\initializer\\initializer.py -> build\\lib.win-amd64-3.8\\gluonnlp\\initializer\n",
      "    copying src\\gluonnlp\\initializer\\__init__.py -> build\\lib.win-amd64-3.8\\gluonnlp\\initializer\n",
      "    creating build\\lib.win-amd64-3.8\\gluonnlp\\loss\n",
      "    copying src\\gluonnlp\\loss\\activation_regularizer.py -> build\\lib.win-amd64-3.8\\gluonnlp\\loss\n",
      "    copying src\\gluonnlp\\loss\\label_smoothing.py -> build\\lib.win-amd64-3.8\\gluonnlp\\loss\n",
      "    copying src\\gluonnlp\\loss\\loss.py -> build\\lib.win-amd64-3.8\\gluonnlp\\loss\n",
      "    copying src\\gluonnlp\\loss\\__init__.py -> build\\lib.win-amd64-3.8\\gluonnlp\\loss\n",
      "    creating build\\lib.win-amd64-3.8\\gluonnlp\\metric\n",
      "    copying src\\gluonnlp\\metric\\length_normalized_loss.py -> build\\lib.win-amd64-3.8\\gluonnlp\\metric\n",
      "    copying src\\gluonnlp\\metric\\masked_accuracy.py -> build\\lib.win-amd64-3.8\\gluonnlp\\metric\n",
      "    copying src\\gluonnlp\\metric\\__init__.py -> build\\lib.win-amd64-3.8\\gluonnlp\\metric\n",
      "    creating build\\lib.win-amd64-3.8\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\attention_cell.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\bert.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\bilm_encoder.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\block.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\convolutional_encoder.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\elmo.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\highway.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\info.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\language_model.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\lstmpcellwithclip.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\parameter.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\sampled_block.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\seq2seq_encoder_decoder.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\sequence_sampler.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\transformer.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\translation.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\utils.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\n",
      "    copying src\\gluonnlp\\model\\__init__.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\n",
      "    creating build\\lib.win-amd64-3.8\\gluonnlp\\optimizer\n",
      "    copying src\\gluonnlp\\optimizer\\bert_adam.py -> build\\lib.win-amd64-3.8\\gluonnlp\\optimizer\n",
      "    copying src\\gluonnlp\\optimizer\\__init__.py -> build\\lib.win-amd64-3.8\\gluonnlp\\optimizer\n",
      "    creating build\\lib.win-amd64-3.8\\gluonnlp\\utils\n",
      "    copying src\\gluonnlp\\utils\\files.py -> build\\lib.win-amd64-3.8\\gluonnlp\\utils\n",
      "    copying src\\gluonnlp\\utils\\parallel.py -> build\\lib.win-amd64-3.8\\gluonnlp\\utils\n",
      "    copying src\\gluonnlp\\utils\\parameter.py -> build\\lib.win-amd64-3.8\\gluonnlp\\utils\n",
      "    copying src\\gluonnlp\\utils\\seed.py -> build\\lib.win-amd64-3.8\\gluonnlp\\utils\n",
      "    copying src\\gluonnlp\\utils\\version.py -> build\\lib.win-amd64-3.8\\gluonnlp\\utils\n",
      "    copying src\\gluonnlp\\utils\\__init__.py -> build\\lib.win-amd64-3.8\\gluonnlp\\utils\n",
      "    creating build\\lib.win-amd64-3.8\\gluonnlp\\vocab\n",
      "    copying src\\gluonnlp\\vocab\\bert.py -> build\\lib.win-amd64-3.8\\gluonnlp\\vocab\n",
      "    copying src\\gluonnlp\\vocab\\elmo.py -> build\\lib.win-amd64-3.8\\gluonnlp\\vocab\n",
      "    copying src\\gluonnlp\\vocab\\subwords.py -> build\\lib.win-amd64-3.8\\gluonnlp\\vocab\n",
      "    copying src\\gluonnlp\\vocab\\vocab.py -> build\\lib.win-amd64-3.8\\gluonnlp\\vocab\n",
      "    copying src\\gluonnlp\\vocab\\__init__.py -> build\\lib.win-amd64-3.8\\gluonnlp\\vocab\n",
      "    creating build\\lib.win-amd64-3.8\\gluonnlp\\data\\batchify\n",
      "    copying src\\gluonnlp\\data\\batchify\\batchify.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\\batchify\n",
      "    copying src\\gluonnlp\\data\\batchify\\embedding.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\\batchify\n",
      "    copying src\\gluonnlp\\data\\batchify\\language_model.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\\batchify\n",
      "    copying src\\gluonnlp\\data\\batchify\\__init__.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\\batchify\n",
      "    creating build\\lib.win-amd64-3.8\\gluonnlp\\data\\bert\n",
      "    copying src\\gluonnlp\\data\\bert\\glue.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\\bert\n",
      "    copying src\\gluonnlp\\data\\bert\\squad.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\\bert\n",
      "    copying src\\gluonnlp\\data\\bert\\__init__.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\\bert\n",
      "    creating build\\lib.win-amd64-3.8\\gluonnlp\\data\\corpora\n",
      "    copying src\\gluonnlp\\data\\corpora\\google_billion_word.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\\corpora\n",
      "    copying src\\gluonnlp\\data\\corpora\\large_text_compression_benchmark.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\\corpora\n",
      "    copying src\\gluonnlp\\data\\corpora\\wikitext.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\\corpora\n",
      "    copying src\\gluonnlp\\data\\corpora\\__init__.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\\corpora\n",
      "    creating build\\lib.win-amd64-3.8\\gluonnlp\\data\\xlnet\n",
      "    copying src\\gluonnlp\\data\\xlnet\\squad.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\\xlnet\n",
      "    copying src\\gluonnlp\\data\\xlnet\\__init__.py -> build\\lib.win-amd64-3.8\\gluonnlp\\data\\xlnet\n",
      "    creating build\\lib.win-amd64-3.8\\gluonnlp\\model\\train\n",
      "    copying src\\gluonnlp\\model\\train\\cache.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\\train\n",
      "    copying src\\gluonnlp\\model\\train\\embedding.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\\train\n",
      "    copying src\\gluonnlp\\model\\train\\language_model.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\\train\n",
      "    copying src\\gluonnlp\\model\\train\\__init__.py -> build\\lib.win-amd64-3.8\\gluonnlp\\model\\train\n",
      "    running egg_info\n",
      "    writing src\\gluonnlp.egg-info\\PKG-INFO\n",
      "    writing dependency_links to src\\gluonnlp.egg-info\\dependency_links.txt\n",
      "    writing requirements to src\\gluonnlp.egg-info\\requires.txt\n",
      "    writing top-level names to src\\gluonnlp.egg-info\\top_level.txt\n",
      "    reading manifest file 'src\\gluonnlp.egg-info\\SOURCES.txt'\n",
      "    reading manifest template 'MANIFEST.in'\n",
      "    warning: no files found matching '*.py' under directory 'gluonnlp'\n",
      "    warning: no previously-included files matching '*' found under directory 'tests'\n",
      "    warning: no previously-included files matching '*' found under directory 'scripts'\n",
      "    writing manifest file 'src\\gluonnlp.egg-info\\SOURCES.txt'\n",
      "    copying src\\gluonnlp\\data\\fast_bert_tokenizer.c -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "    copying src\\gluonnlp\\data\\fast_bert_tokenizer.pyx -> build\\lib.win-amd64-3.8\\gluonnlp\\data\n",
      "    running build_ext\n",
      "    skipping 'src/gluonnlp/data\\fast_bert_tokenizer.c' Cython extension (up-to-date)\n",
      "    building 'gluonnlp.data.fast_bert_tokenizer' extension\n",
      "    error: Microsoft Visual C++ 14.0 is required. Get it with \"Build Tools for Visual Studio\": https://visualstudio.microsoft.com/downloads/\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'C:\\ProgramData\\Anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\강의장\\\\AppData\\\\Local\\\\Temp\\\\pip-install-6yaywths\\\\gluonnlp\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\강의장\\\\AppData\\\\Local\\\\Temp\\\\pip-install-6yaywths\\\\gluonnlp\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\강의장\\AppData\\Local\\Temp\\pip-record-7i3o1_ny\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\ProgramData\\Anaconda3\\Include\\gluonnlp' Check the logs for full command output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece==0.1.85 in c:\\programdata\\anaconda3\\lib\\site-packages (0.1.85)\n",
      "Requirement already satisfied: transformers==2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: sacremoses in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers==2.1.1) (0.0.43)\n",
      "Requirement already satisfied: boto3 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers==2.1.1) (1.15.16)\n",
      "Requirement already satisfied: regex in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers==2.1.1) (2020.6.8)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers==2.1.1) (4.47.0)\n",
      "Requirement already satisfied: sentencepiece in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers==2.1.1) (0.1.85)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers==2.1.1) (2.24.0)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers==2.1.1) (1.18.5)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from sacremoses->transformers==2.1.1) (1.15.0)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from sacremoses->transformers==2.1.1) (0.16.0)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from sacremoses->transformers==2.1.1) (7.1.2)\n",
      "Requirement already satisfied: botocore<1.19.0,>=1.18.16 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3->transformers==2.1.1) (1.18.16)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3->transformers==2.1.1) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3->transformers==2.1.1) (0.10.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers==2.1.1) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers==2.1.1) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers==2.1.1) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers==2.1.1) (1.25.9)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from botocore<1.19.0,>=1.18.16->boto3->transformers==2.1.1) (2.8.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement torch==1.3.1 (from versions: 0.1.2, 0.1.2.post1, 0.1.2.post2)\n",
      "ERROR: No matching distribution found for torch==1.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install mxnet-cu101\n",
    "!pip install gluonnlp pandas tqdm\n",
    "!pip install sentencepiece==0.1.85\n",
    "!pip install transformers==2.1.1\n",
    "!pip install torch==1.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "from transformers.optimization import WarmupLinearSchedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##GPU 사용 시\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertmodel, vocab = get_pytorch_kobert_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/374ftkec978br3d/ratings_train.txt?dl=1\n",
    "!wget https://www.dropbox.com/s/977gbwh542gdy94/ratings_test.txt?dl=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = nlp.data.TSVDataset(\"ratings_train.txt?dl=1\", field_indices=[1,2], num_discard_samples=1)\n",
    "dataset_test = nlp.data.TSVDataset(\"ratings_test.txt?dl=1\", field_indices=[1,2], num_discard_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting parameters\n",
    "max_len = 64\n",
    "batch_size = 64\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 5\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate =  5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n",
    "data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
    "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=2,\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare optimizer and schedule (linear warmup and decay)\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_total = len(train_dataloader) * num_epochs\n",
    "warmup_step = int(t_total * warmup_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = WarmupLinearSchedule(optimizer, warmup_steps=warmup_step, t_total=t_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(X,Y):\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(num_epochs):\n",
    "    train_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "    model.train()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        loss = loss_fn(out, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update learning rate schedule\n",
    "        train_acc += calc_accuracy(out, label)\n",
    "        if batch_id % log_interval == 0:\n",
    "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
    "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
    "    model.eval()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        test_acc += calc_accuracy(out, label)\n",
    "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
