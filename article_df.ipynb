{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "\n",
    "url = 'https://www.asiae.co.kr/'\n",
    "\n",
    "# 페이지 이동\n",
    "driver.get(url)\n",
    "time.sleep(1)\n",
    "\n",
    "driver.find_element_by_css_selector('#main_wrap > div.main_header > div.top_head > div.area_fstare > div > div > div.search_wrap > form > fieldset > a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1          삼성전자\n",
       "2        SK하이닉스\n",
       "3      삼성바이오로직스\n",
       "4         NAVER\n",
       "5           현대차\n",
       "         ...   \n",
       "196        고려제강\n",
       "197        한국단자\n",
       "198        한세실업\n",
       "199        대덕전자\n",
       "200     한올바이오파마\n",
       "Name: name, Length: 200, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kospi200_csv = pd.read_csv('KOSPI200_LIST.csv',names = ['index', 'name'], header = None)\n",
    "kospi200_csv = kospi200_csv.drop(index = 0)\n",
    "kospi200 = kospi200_csv['name']\n",
    "kospi200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#리스트 추가 # 리스트 목록으로 만들어서 for 문으로 돌리자\n",
    "kospi200 = '한라홀딩스'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색목록에 넣기\n",
    "e = driver.find_element_by_css_selector('#search1')\n",
    "e.send_keys(kospi200)\n",
    "# 검색버튼 누르기\n",
    "driver.find_element_by_css_selector('#main_wrap > div.main_header > div.top_head > div.area_fstare > div > div > div.search_wrap > form > fieldset > div > input').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#뉴스 목록 선택\n",
    "driver.find_element_by_css_selector('#type_news > a > span').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#검색옵션 선택\n",
    "driver.find_element_by_css_selector(\"#wrap > div.seo_lnb > div.sch_lnb > div > a > span\").click()\n",
    "time.sleep(0.5)\n",
    "#기간 필터 클릭\n",
    "driver.find_element_by_css_selector(\"#wrap > div.seo_lnb > div.sch_lst > div > div > ul > li.title_tab.tab02 > a > span\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#기간 입력 및 적용\n",
    "\n",
    "inputsDate = driver.find_element_by_css_selector('#sDate')\n",
    "inputsDate.send_keys('2014.09.01')\n",
    "driver.find_element_by_css_selector(\"#ui-datepicker-div > div.ui-datepicker-buttonpane.ui-widget-content > button.ui-datepicker-close.ui-state-default.ui-priority-primary.ui-corner-all\").click()\n",
    "time.sleep(0.5)\n",
    "inputeDate = driver.find_element_by_css_selector('#eDate')\n",
    "inputeDate.send_keys('2020.08.31')\n",
    "driver.find_element_by_css_selector(\"#ui-datepicker-div > div.ui-datepicker-buttonpane.ui-widget-content > button.ui-datepicker-close.ui-state-default.ui-priority-primary.ui-corner-all\").click()\n",
    "\n",
    "time.sleep(0.5)\n",
    "\n",
    "driver.find_element_by_css_selector(\"#wrap > div.seo_lnb > div.sch_lst > div > div > div > ul.tcont.tabcont02.on > li.inp_box > div > a\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #섹션 선택\n",
    "# driver.find_element_by_css_selector('#container > div.content > div > div > h3 > div.ns_btn > a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver.find_element_by_css_selector('#container > div.content > div > div > h3 > div.ns_btn > a > span').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# article_df = pd.DataFrame(columns = ['Title', 'Date','Category'])\n",
    "# for section in range(2,12):\n",
    "#     #섹션 선택\n",
    "#     driver.find_element_by_css_selector('#container > div.content > div > div > h3 > div.ns_btn > a > span').click()\n",
    "#     time.sleep(0.5)\n",
    "#     driver.find_element_by_css_selector('#container > div.content > div > div > h3 > div.ns_wrap > ul > li:nth-child({}) > a'.format(section)).click()\n",
    "#     time.sleep(2)\n",
    "#     #beautifulsoup으로 크롤링하기\n",
    "#     html = driver.page_source\n",
    "#     soup = BeautifulSoup(html, 'html.parser')\n",
    "# #     total_count = soup.body.select_one('#container > div.content > div > div > h3 > span')\n",
    "# #     total_count = int(total_count.string[2:-1].replace(\",\",\"\"))\n",
    "# #     pages = total_count/15\n",
    "#     leng = soup.body.select('#container > div > div > div > ul')\n",
    "#     a = leng[0].find_all('li')\n",
    "#     for i in a:\n",
    "#         temp_t = i.find('span', class_='tit')\n",
    "#         temp_d =i.find('span',class_='dt_t')\n",
    "#         # category 는 후에 위에 다른 변수에서 설정해서 퍼와야할듯\n",
    "#         article_df = article_df.append({'Title' : temp_t.a.text.strip(), 'Date':temp_d.string[:10], 'Category':section}, ignore_index = True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# article_df = pd.DataFrame(columns = ['Title', 'Date','Category'])\n",
    "# for section in range(5,12):\n",
    "#     #섹션 선택\n",
    "#     driver.find_element_by_css_selector('#container > div.content > div > div > h3 > div.ns_btn > a > span').click()\n",
    "#     time.sleep(0.5)\n",
    "#     driver.find_element_by_css_selector('#container > div.content > div > div > h3 > div.ns_wrap > ul > li:nth-child({}) > a'.format(section)).click()\n",
    "#     time.sleep(2)\n",
    "#     #beautifulsoup으로 크롤링하기\n",
    "#     html = driver.page_source\n",
    "#     soup = BeautifulSoup(html, 'html.parser')\n",
    "#     total_count = soup.body.select_one('#container > div.content > div > div > h3 > span')\n",
    "#     total_count = int(total_count.string[2:-1].replace(\",\",\"\"))\n",
    "#     pages = total_count//15 +1\n",
    "#     leng = soup.body.select('#container > div > div > div > ul')\n",
    "#     a = leng[0].find_all('li')\n",
    "#     for page in range(2, pages +1):\n",
    "#         # 1페이지 크롤링\n",
    "#         for i in a:\n",
    "#             temp_t = i.find('span', class_='tit')\n",
    "#             temp_d =i.find('span',class_='dt_t')\n",
    "#             # category 는 후에 위에 다른 변수에서 설정해서 퍼와야할듯\n",
    "#             article_df = article_df.append({'Title' : temp_t.a.text.strip(), 'Date':temp_d.string[:10], 'Category':section}, ignore_index = True)\n",
    "#         # 페이지가 1페이지밖에 없다면 다음 페이지 실행 안함\n",
    "#         if pages != 1:\n",
    "#             if int(page) %10 != 1 :\n",
    "#                 driver.find_element_by_link_text(str(page)).click()\n",
    "#                 time.sleep(1)\n",
    "#                 #페이지 변경 후 parser\n",
    "#                 html = driver.page_source\n",
    "#                 soup = BeautifulSoup(html, 'html.parser')\n",
    "#                 for i in a:\n",
    "#                     temp_t = i.find('span', class_='tit')\n",
    "#                     temp_d =i.find('span',class_='dt_t')\n",
    "#                     # category 는 후에 위에 다른 변수에서 설정해서 퍼와야할듯\n",
    "#                     article_df = article_df.append({'Title' : temp_t.a.text.strip(), 'Date':temp_d.string[:10], 'Category':section}, ignore_index = True)\n",
    "#             else:\n",
    "                \n",
    "#             # 10단위 페이지 이후 다음 버튼 클릭\n",
    "#                 driver.find_element_by_css_selector('#container > div > div > div > em > div > span > a.btn_paging.btn_next').click()\n",
    "#                 time.sleep(0.5)\n",
    "#                 for i in a:\n",
    "#                     temp_t = i.find('span', class_='tit')\n",
    "#                     temp_d =i.find('span',class_='dt_t')\n",
    "#                     # category 는 후에 위에 다른 변수에서 설정해서 퍼와야할듯\n",
    "#                     article_df = article_df.append({'Title' : temp_t.a.text.strip(), 'Date':temp_d.string[:10], 'Category':section}, ignore_index = True)\n",
    "#             time.sleep(1)\n",
    "#             page +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# page_bar = driver.find_elements_by_css_selector('div.paging_comm > span.inner_paging > *')\n",
    "# page_bar[0].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "article_df = pd.DataFrame(columns = ['Title', 'Date','Category'])\n",
    "for section in range(2,12):\n",
    "    #섹션 선택\n",
    "    driver.find_element_by_css_selector('#container > div.content > div > div > h3 > div.ns_btn > a > span').click()\n",
    "    time.sleep(0.5)\n",
    "    driver.find_element_by_css_selector('#container > div.content > div > div > h3 > div.ns_wrap > ul > li:nth-child({}) > a'.format(section)).click()\n",
    "    time.sleep(2)\n",
    "    # total count를 크롤링해서 전체 페이지 수를 체킹\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    total_count = soup.body.select_one('#container > div.content > div > div > h3 > span')\n",
    "    #섹션에 뉴스가 없을 경우 다음 섹션으로 이동\n",
    "    if total_count is None:\n",
    "        driver.back()\n",
    "        time.sleep(1)\n",
    "        continue\n",
    "    #페이지 수 구하기\n",
    "    total_count = int(total_count.string[2:-1].replace(\",\",\"\"))\n",
    "    pages = total_count//15 + 1\n",
    "    for page in range(pages):\n",
    "        # 페이지 바에 대한 셀레늄을 리스트로 가져와서 페이지에 따라 선택\n",
    "        page_bar = driver.find_elements_by_css_selector('div.paging_comm > span.inner_paging > *')\n",
    "        # 처음 시작할때는 페이지바 안누르기\n",
    "        if page != 0:\n",
    "            if page%10 != 0:\n",
    "                page_bar[page%10].click()\n",
    "            else :\n",
    "                page_bar[len(page_bar)-1].click()\n",
    "        time.sleep(0.5)\n",
    "        #beautifulsoup으로 크롤링하기\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        leng = soup.body.select('#container > div > div > div > ul')\n",
    "        a = leng[0].find_all('li')\n",
    "        for i in a:\n",
    "            temp_t = i.find('span', class_='tit')\n",
    "            temp_d =i.find('span',class_='dt_t')\n",
    "            # category 는 후에 위에 다른 변수에서 설정해서 퍼와야할듯\n",
    "            article_df = article_df.append({'Title' : temp_t.a.text.strip(), 'Date':temp_d.string[:10], 'Category':section}, ignore_index = True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>지주회사의 민낯…내부거래 비중 55%</td>\n",
       "      <td>2018.07.03</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[슈퍼주총]삼성 주주친화 vs SK 행복 vs 롯데 책임경영…924개사 메가주총</td>\n",
       "      <td>2017.03.24</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>한라, 성공적 자구 완료…차입금 8000억 줄여</td>\n",
       "      <td>2016.03.10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>한라홀딩스, KS 블랙박스 '만도 KP100' 출시</td>\n",
       "      <td>2016.03.02</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>한라, 계열사 한라홀딩스가 4600주 장내매수</td>\n",
       "      <td>2016.01.28</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>한라, 물류창고 사업 진출 본격화…\"미래가치 우수\"</td>\n",
       "      <td>2015.07.23</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>익산소방서, 물류창고 화재안전 긴급 점검</td>\n",
       "      <td>2020.08.21</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>車 특허기술, 자율주행 등 '전환'…현·기차 업계 특허출원 ‘주도’</td>\n",
       "      <td>2016.05.22</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>[부고]이주형(한라홀딩스 상무)씨 장인상</td>\n",
       "      <td>2015.08.02</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>한라, 한라홀딩스·만도 지분 처분</td>\n",
       "      <td>2014.11.06</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Title        Date Category\n",
       "0                            지주회사의 민낯…내부거래 비중 55%  2018.07.03        3\n",
       "1    [슈퍼주총]삼성 주주친화 vs SK 행복 vs 롯데 책임경영…924개사 메가주총  2017.03.24        3\n",
       "2                      한라, 성공적 자구 완료…차입금 8000억 줄여  2016.03.10        3\n",
       "3                    한라홀딩스, KS 블랙박스 '만도 KP100' 출시  2016.03.02        3\n",
       "4                       한라, 계열사 한라홀딩스가 4600주 장내매수  2016.01.28        3\n",
       "..                                            ...         ...      ...\n",
       "173                  한라, 물류창고 사업 진출 본격화…\"미래가치 우수\"  2015.07.23        6\n",
       "174                        익산소방서, 물류창고 화재안전 긴급 점검  2020.08.21        8\n",
       "175         車 특허기술, 자율주행 등 '전환'…현·기차 업계 특허출원 ‘주도’  2016.05.22        8\n",
       "176                        [부고]이주형(한라홀딩스 상무)씨 장인상  2015.08.02        8\n",
       "177                            한라, 한라홀딩스·만도 지분 처분  2014.11.06        8\n",
       "\n",
       "[178 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
